{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torchvision.datasets as datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import numpy as np\n",
    "\n",
    "# Transformations\n",
    "RC   = transforms.RandomCrop(32, padding=4)\n",
    "RHF  = transforms.RandomHorizontalFlip()\n",
    "RVF  = transforms.RandomVerticalFlip()\n",
    "NRM  = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "TT   = transforms.ToTensor()\n",
    "TPIL = transforms.ToPILImage()\n",
    "\n",
    "# Transforms object for trainset with augmentation\n",
    "transform_with_aug = transforms.Compose([TPIL, RC, RHF, TT, NRM])\n",
    "# Transforms object for testset with NO augmentation\n",
    "transform_no_aug   = transforms.Compose([TT, NRM])\n",
    "\n",
    "# Downloading/Louding CIFAR10 data\n",
    "trainset  = CIFAR10(root='/DATA/Ravi10/Data/CIFAR_10/', train=True , download=True)#, transform = transform_with_aug)\n",
    "testset   = CIFAR10(root='/DATA/Ravi10/Data/CIFAR_10/', train=False, download=True)#, transform = transform_no_aug)\n",
    "classDict = {'plane':0, 'car':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\n",
    "\n",
    "# Separating trainset/testset data/label\n",
    "x_train  = trainset.data\n",
    "x_test   = testset.data\n",
    "y_train  = trainset.targets\n",
    "y_test   = testset.targets\n",
    "\n",
    "# Define a function to separate CIFAR classes by class index\n",
    "\n",
    "def get_class_i(x, y, i):\n",
    "    \"\"\"\n",
    "    x: trainset.train_data or testset.test_data\n",
    "    y: trainset.train_labels or testset.test_labels\n",
    "    i: class label, a number between 0 to 9\n",
    "    return: x_i\n",
    "    \"\"\"\n",
    "    # Convert to a numpy array\n",
    "    y = np.array(y)\n",
    "    # Locate position of labels that equal to i\n",
    "    pos_i = np.argwhere(y == i)\n",
    "    # Convert the result into a 1-D list\n",
    "    pos_i = list(pos_i[:,0])\n",
    "    # Collect all data that match the desired label\n",
    "    x_i = [x[j] for j in pos_i]\n",
    "    \n",
    "    return x_i\n",
    "\n",
    "class DatasetMaker(Dataset):\n",
    "    def __init__(self, datasets, transformFunc = transform_no_aug):\n",
    "        \"\"\"\n",
    "        datasets: a list of get_class_i outputs, i.e. a list of list of images for selected classes\n",
    "        \"\"\"\n",
    "        self.datasets = datasets\n",
    "        self.lengths  = [len(d) for d in self.datasets]\n",
    "        self.transformFunc = transformFunc\n",
    "    def __getitem__(self, i):\n",
    "        class_label, index_wrt_class = self.index_of_which_bin(self.lengths, i)\n",
    "        img = self.datasets[class_label][index_wrt_class]\n",
    "        img = self.transformFunc(img)\n",
    "        return img, class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.lengths)\n",
    "    \n",
    "    def index_of_which_bin(self, bin_sizes, absolute_index, verbose=False):\n",
    "        \"\"\"\n",
    "        Given the absolute index, returns which bin it falls in and which element of that bin it corresponds to.\n",
    "        \"\"\"\n",
    "        # Which class/bin does i fall into?\n",
    "        accum = np.add.accumulate(bin_sizes)\n",
    "        if verbose:\n",
    "            print(\"accum =\", accum)\n",
    "        bin_index  = len(np.argwhere(accum <= absolute_index))\n",
    "        if verbose:\n",
    "            print(\"class_label =\", bin_index)\n",
    "        # Which element of the fallent class/bin does i correspond to?\n",
    "        index_wrt_class = absolute_index - np.insert(accum, 0, 0)[bin_index]\n",
    "        if verbose:\n",
    "            print(\"index_wrt_class =\", index_wrt_class)\n",
    "\n",
    "        return bin_index, index_wrt_class\n",
    "\n",
    "# ================== Usage ================== #\n",
    "\n",
    "# Let's choose cats (class 3 of CIFAR) and dogs (class 5 of CIFAR) as trainset/testset\n",
    "my_trainset = \\\n",
    "    DatasetMaker(\n",
    "        [get_class_i(x_train, y_train, classDict['plane']), get_class_i(x_train, y_train, classDict['car']),get_class_i(x_train, y_train, classDict['bird']),get_class_i(x_train, y_train, classDict['cat']),get_class_i(x_train, y_train, classDict['deer'])],\n",
    "        transform_with_aug\n",
    "    )\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_testset = DatasetMaker(\n",
    "        [get_class_i(x_train, y_train, classDict['plane']), get_class_i(x_train, y_train, classDict['car']),get_class_i(x_train, y_train, classDict['bird']),get_class_i(x_train, y_train, classDict['cat']),get_class_i(x_train, y_train, classDict['deer'])],\n",
    "        transform_no_aug\n",
    "    )\n",
    "\n",
    "kwargs = {'num_workers': 2, 'pin_memory': False}\n",
    "\n",
    "# Create datasetLoaders from trainset and testset\n",
    "trainsetLoader   = DataLoader(my_trainset, batch_size=64, shuffle=True , **kwargs)\n",
    "testsetLoader    = DataLoader(my_testset , batch_size=64, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lenet,self).__init__()\n",
    "        self.layer1 = nn.Conv2d(3,6,kernel_size=5,stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.layer2 = nn.Conv2d(6,16,kernel_size=5,stride=1)\n",
    "        #self.layer3 = nn.Conv2d(16,120,kernel_size=5,stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.smax = nn.Softmax()\n",
    "        self.fc1 = nn.Linear(400,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.out = nn.Linear(84,5)\n",
    "    def forward(self,x):\n",
    "        a = self.relu(self.layer1(x))\n",
    "        a = self.relu(self.pool1(a))\n",
    "        a = self.relu(self.layer2(a))\n",
    "        a = self.relu(self.pool1(a))\n",
    "        #a = self.layer3(a)\n",
    "        #print(a.size)\n",
    "        b = a.view(a.shape[0],-1)\n",
    "        b = self.relu(self.fc1(b))\n",
    "        b = self.relu(self.fc2(b))\n",
    "        out = self.out(b)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lenet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.1,momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for i,(inputs,targets) in enumerate(trainsetLoader):\n",
    "        inputs = Variable(inputs)\n",
    "        inputs = inputs.to(device)\n",
    "        targets = Variable(targets)\n",
    "        targets = targets.to(device)\n",
    "        #print(targets.shape)\n",
    "        preds = model(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(preds,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%100 == 0:\n",
    "            temp = 100.*i*len(inputs)/len(trainsetLoader.dataset)\n",
    "            print('Epoch:{} [{}/{}] {:.0f}% Loss:{:.4f}'.format(epoch,i*len(inputs),len(trainsetLoader.dataset),temp,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs,targets in testsetLoader:\n",
    "            inputs = Variable(inputs)\n",
    "            inputs = inputs.to(device)\n",
    "            targets = Variable(targets)\n",
    "            targets = targets.to(device)\n",
    "            preds = model(inputs)\n",
    "            test_loss += criterion(preds,targets)\n",
    "            label = torch.max(preds,1)[1]\n",
    "            correct += label.eq(targets.view_as(label)).cpu().sum()\n",
    "        test_loss /= len(testsetLoader.dataset)\n",
    "        acc = 100.*correct/len(testsetLoader.dataset)\n",
    "        print('\\nTest Error:{:.4f} Correct:{} Accuracy:{:.4f}'.format(test_loss,correct,acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 [0/25000] 0% Loss:1.6008\n",
      "Epoch:1 [6400/25000] 26% Loss:1.3381\n",
      "Epoch:1 [12800/25000] 51% Loss:1.0976\n",
      "Epoch:1 [19200/25000] 77% Loss:1.2852\n",
      "\n",
      "Test Error:0.0156 Correct:14816 Accuracy:59.2640\n",
      "Epoch:2 [0/25000] 0% Loss:1.0151\n",
      "Epoch:2 [6400/25000] 26% Loss:1.1768\n",
      "Epoch:2 [12800/25000] 51% Loss:1.0334\n",
      "Epoch:2 [19200/25000] 77% Loss:0.8002\n",
      "\n",
      "Test Error:0.0154 Correct:14606 Accuracy:58.4240\n",
      "Epoch:3 [0/25000] 0% Loss:1.0519\n",
      "Epoch:3 [6400/25000] 26% Loss:0.9489\n",
      "Epoch:3 [12800/25000] 51% Loss:1.0462\n",
      "Epoch:3 [19200/25000] 77% Loss:0.9706\n",
      "\n",
      "Test Error:0.0139 Correct:16289 Accuracy:65.1560\n",
      "Epoch:4 [0/25000] 0% Loss:0.8400\n",
      "Epoch:4 [6400/25000] 26% Loss:0.9293\n",
      "Epoch:4 [12800/25000] 51% Loss:0.9528\n",
      "Epoch:4 [19200/25000] 77% Loss:1.1105\n",
      "\n",
      "Test Error:0.0147 Correct:15752 Accuracy:63.0080\n",
      "Epoch:5 [0/25000] 0% Loss:0.9509\n",
      "Epoch:5 [6400/25000] 26% Loss:0.8358\n",
      "Epoch:5 [12800/25000] 51% Loss:0.8524\n",
      "Epoch:5 [19200/25000] 77% Loss:0.9723\n",
      "\n",
      "Test Error:0.0141 Correct:16142 Accuracy:64.5680\n",
      "Epoch:6 [0/25000] 0% Loss:0.8898\n",
      "Epoch:6 [6400/25000] 26% Loss:0.9141\n",
      "Epoch:6 [12800/25000] 51% Loss:0.8035\n",
      "Epoch:6 [19200/25000] 77% Loss:0.8249\n",
      "\n",
      "Test Error:0.0130 Correct:16932 Accuracy:67.7280\n",
      "Epoch:7 [0/25000] 0% Loss:0.7566\n",
      "Epoch:7 [6400/25000] 26% Loss:0.7715\n",
      "Epoch:7 [12800/25000] 51% Loss:0.9837\n",
      "Epoch:7 [19200/25000] 77% Loss:1.0528\n",
      "\n",
      "Test Error:0.0131 Correct:16898 Accuracy:67.5920\n",
      "Epoch:8 [0/25000] 0% Loss:0.9953\n",
      "Epoch:8 [6400/25000] 26% Loss:0.8797\n",
      "Epoch:8 [12800/25000] 51% Loss:1.1452\n",
      "Epoch:8 [19200/25000] 77% Loss:1.0321\n",
      "\n",
      "Test Error:0.0133 Correct:16554 Accuracy:66.2160\n",
      "Epoch:9 [0/25000] 0% Loss:0.7533\n",
      "Epoch:9 [6400/25000] 26% Loss:0.9189\n",
      "Epoch:9 [12800/25000] 51% Loss:0.7575\n",
      "Epoch:9 [19200/25000] 77% Loss:0.9032\n",
      "\n",
      "Test Error:0.0125 Correct:17322 Accuracy:69.2880\n",
      "Epoch:10 [0/25000] 0% Loss:0.6832\n",
      "Epoch:10 [6400/25000] 26% Loss:0.8510\n",
      "Epoch:10 [12800/25000] 51% Loss:0.9913\n",
      "Epoch:10 [19200/25000] 77% Loss:0.8286\n",
      "\n",
      "Test Error:0.0119 Correct:17709 Accuracy:70.8360\n",
      "Epoch:11 [0/25000] 0% Loss:0.9291\n",
      "Epoch:11 [6400/25000] 26% Loss:0.7381\n",
      "Epoch:11 [12800/25000] 51% Loss:0.7968\n",
      "Epoch:11 [19200/25000] 77% Loss:0.7270\n",
      "\n",
      "Test Error:0.0129 Correct:17249 Accuracy:68.9960\n",
      "Epoch:12 [0/25000] 0% Loss:0.9512\n",
      "Epoch:12 [6400/25000] 26% Loss:0.7769\n",
      "Epoch:12 [12800/25000] 51% Loss:0.8522\n",
      "Epoch:12 [19200/25000] 77% Loss:0.9903\n",
      "\n",
      "Test Error:0.0119 Correct:17883 Accuracy:71.5320\n",
      "Epoch:13 [0/25000] 0% Loss:0.8591\n",
      "Epoch:13 [6400/25000] 26% Loss:0.6794\n",
      "Epoch:13 [12800/25000] 51% Loss:0.8422\n",
      "Epoch:13 [19200/25000] 77% Loss:0.7569\n",
      "\n",
      "Test Error:0.0113 Correct:18082 Accuracy:72.3280\n",
      "Epoch:14 [0/25000] 0% Loss:0.6615\n",
      "Epoch:14 [6400/25000] 26% Loss:0.9410\n",
      "Epoch:14 [12800/25000] 51% Loss:0.8306\n",
      "Epoch:14 [19200/25000] 77% Loss:0.7431\n",
      "\n",
      "Test Error:0.0132 Correct:16941 Accuracy:67.7640\n",
      "Epoch:15 [0/25000] 0% Loss:0.9353\n",
      "Epoch:15 [6400/25000] 26% Loss:0.7581\n",
      "Epoch:15 [12800/25000] 51% Loss:0.5943\n",
      "Epoch:15 [19200/25000] 77% Loss:0.7524\n",
      "\n",
      "Test Error:0.0116 Correct:18041 Accuracy:72.1640\n",
      "Epoch:16 [0/25000] 0% Loss:0.5388\n",
      "Epoch:16 [6400/25000] 26% Loss:0.7629\n",
      "Epoch:16 [12800/25000] 51% Loss:0.7256\n",
      "Epoch:16 [19200/25000] 77% Loss:0.7287\n",
      "\n",
      "Test Error:0.0119 Correct:17727 Accuracy:70.9080\n",
      "Epoch:17 [0/25000] 0% Loss:0.7744\n",
      "Epoch:17 [6400/25000] 26% Loss:0.8063\n",
      "Epoch:17 [12800/25000] 51% Loss:0.5781\n",
      "Epoch:17 [19200/25000] 77% Loss:0.7720\n",
      "\n",
      "Test Error:0.0115 Correct:18057 Accuracy:72.2280\n",
      "Epoch:18 [0/25000] 0% Loss:0.6463\n",
      "Epoch:18 [6400/25000] 26% Loss:0.9709\n",
      "Epoch:18 [12800/25000] 51% Loss:0.9384\n",
      "Epoch:18 [19200/25000] 77% Loss:0.8710\n",
      "\n",
      "Test Error:0.0113 Correct:18057 Accuracy:72.2280\n",
      "Epoch:19 [0/25000] 0% Loss:1.1945\n",
      "Epoch:19 [6400/25000] 26% Loss:0.5938\n",
      "Epoch:19 [12800/25000] 51% Loss:0.6223\n",
      "Epoch:19 [19200/25000] 77% Loss:0.7021\n",
      "\n",
      "Test Error:0.0107 Correct:18588 Accuracy:74.3520\n",
      "Epoch:20 [0/25000] 0% Loss:0.7467\n",
      "Epoch:20 [6400/25000] 26% Loss:0.8025\n",
      "Epoch:20 [12800/25000] 51% Loss:0.8456\n",
      "Epoch:20 [19200/25000] 77% Loss:0.9367\n",
      "\n",
      "Test Error:0.0124 Correct:17401 Accuracy:69.6040\n",
      "Epoch:21 [0/25000] 0% Loss:0.9399\n",
      "Epoch:21 [6400/25000] 26% Loss:0.4536\n",
      "Epoch:21 [12800/25000] 51% Loss:0.5823\n",
      "Epoch:21 [19200/25000] 77% Loss:0.7482\n",
      "\n",
      "Test Error:0.0097 Correct:19123 Accuracy:76.4920\n",
      "Epoch:22 [0/25000] 0% Loss:0.7083\n",
      "Epoch:22 [6400/25000] 26% Loss:0.7345\n",
      "Epoch:22 [12800/25000] 51% Loss:0.5627\n",
      "Epoch:22 [19200/25000] 77% Loss:0.6151\n",
      "\n",
      "Test Error:0.0096 Correct:19203 Accuracy:76.8120\n",
      "Epoch:23 [0/25000] 0% Loss:0.7785\n",
      "Epoch:23 [6400/25000] 26% Loss:0.6576\n",
      "Epoch:23 [12800/25000] 51% Loss:0.6730\n",
      "Epoch:23 [19200/25000] 77% Loss:0.6477\n",
      "\n",
      "Test Error:0.0094 Correct:19296 Accuracy:77.1840\n",
      "Epoch:24 [0/25000] 0% Loss:0.4884\n",
      "Epoch:24 [6400/25000] 26% Loss:0.6281\n",
      "Epoch:24 [12800/25000] 51% Loss:0.6660\n",
      "Epoch:24 [19200/25000] 77% Loss:0.6320\n",
      "\n",
      "Test Error:0.0094 Correct:19305 Accuracy:77.2200\n",
      "Epoch:25 [0/25000] 0% Loss:0.5570\n",
      "Epoch:25 [6400/25000] 26% Loss:0.5465\n",
      "Epoch:25 [12800/25000] 51% Loss:0.6723\n",
      "Epoch:25 [19200/25000] 77% Loss:0.7800\n",
      "\n",
      "Test Error:0.0092 Correct:19455 Accuracy:77.8200\n",
      "Epoch:26 [0/25000] 0% Loss:0.4612\n",
      "Epoch:26 [6400/25000] 26% Loss:0.7859\n",
      "Epoch:26 [12800/25000] 51% Loss:0.5580\n",
      "Epoch:26 [19200/25000] 77% Loss:0.5264\n",
      "\n",
      "Test Error:0.0092 Correct:19449 Accuracy:77.7960\n",
      "Epoch:27 [0/25000] 0% Loss:0.6039\n",
      "Epoch:27 [6400/25000] 26% Loss:0.7088\n",
      "Epoch:27 [12800/25000] 51% Loss:0.6121\n",
      "Epoch:27 [19200/25000] 77% Loss:0.6523\n",
      "\n",
      "Test Error:0.0091 Correct:19461 Accuracy:77.8440\n",
      "Epoch:28 [0/25000] 0% Loss:0.5432\n",
      "Epoch:28 [6400/25000] 26% Loss:0.6052\n",
      "Epoch:28 [12800/25000] 51% Loss:0.5981\n",
      "Epoch:28 [19200/25000] 77% Loss:0.6894\n",
      "\n",
      "Test Error:0.0090 Correct:19537 Accuracy:78.1480\n",
      "Epoch:29 [0/25000] 0% Loss:0.5483\n",
      "Epoch:29 [6400/25000] 26% Loss:0.6268\n",
      "Epoch:29 [12800/25000] 51% Loss:0.8060\n",
      "Epoch:29 [19200/25000] 77% Loss:0.6140\n",
      "\n",
      "Test Error:0.0090 Correct:19549 Accuracy:78.1960\n",
      "Epoch:30 [0/25000] 0% Loss:0.7751\n",
      "Epoch:30 [6400/25000] 26% Loss:0.7302\n",
      "Epoch:30 [12800/25000] 51% Loss:0.7999\n",
      "Epoch:30 [19200/25000] 77% Loss:0.5363\n",
      "\n",
      "Test Error:0.0089 Correct:19625 Accuracy:78.5000\n",
      "Epoch:31 [0/25000] 0% Loss:0.6197\n",
      "Epoch:31 [6400/25000] 26% Loss:0.5037\n",
      "Epoch:31 [12800/25000] 51% Loss:0.5464\n",
      "Epoch:31 [19200/25000] 77% Loss:0.6793\n",
      "\n",
      "Test Error:0.0088 Correct:19637 Accuracy:78.5480\n",
      "Epoch:32 [0/25000] 0% Loss:0.8304\n",
      "Epoch:32 [6400/25000] 26% Loss:0.5647\n",
      "Epoch:32 [12800/25000] 51% Loss:0.5736\n",
      "Epoch:32 [19200/25000] 77% Loss:0.4838\n",
      "\n",
      "Test Error:0.0088 Correct:19652 Accuracy:78.6080\n",
      "Epoch:33 [0/25000] 0% Loss:0.5182\n",
      "Epoch:33 [6400/25000] 26% Loss:0.6330\n",
      "Epoch:33 [12800/25000] 51% Loss:0.7708\n",
      "Epoch:33 [19200/25000] 77% Loss:0.8953\n",
      "\n",
      "Test Error:0.0089 Correct:19639 Accuracy:78.5560\n",
      "Epoch:34 [0/25000] 0% Loss:0.5844\n",
      "Epoch:34 [6400/25000] 26% Loss:0.6869\n",
      "Epoch:34 [12800/25000] 51% Loss:0.5489\n",
      "Epoch:34 [19200/25000] 77% Loss:0.7141\n",
      "\n",
      "Test Error:0.0089 Correct:19652 Accuracy:78.6080\n",
      "Epoch:35 [0/25000] 0% Loss:0.5206\n",
      "Epoch:35 [6400/25000] 26% Loss:0.6280\n",
      "Epoch:35 [12800/25000] 51% Loss:0.4192\n",
      "Epoch:35 [19200/25000] 77% Loss:0.6793\n",
      "\n",
      "Test Error:0.0088 Correct:19681 Accuracy:78.7240\n",
      "Epoch:36 [0/25000] 0% Loss:0.4698\n",
      "Epoch:36 [6400/25000] 26% Loss:0.8667\n",
      "Epoch:36 [12800/25000] 51% Loss:0.6437\n",
      "Epoch:36 [19200/25000] 77% Loss:0.6164\n",
      "\n",
      "Test Error:0.0088 Correct:19689 Accuracy:78.7560\n",
      "Epoch:37 [0/25000] 0% Loss:0.6199\n",
      "Epoch:37 [6400/25000] 26% Loss:0.6294\n",
      "Epoch:37 [12800/25000] 51% Loss:0.7040\n",
      "Epoch:37 [19200/25000] 77% Loss:0.7537\n",
      "\n",
      "Test Error:0.0086 Correct:19807 Accuracy:79.2280\n",
      "Epoch:38 [0/25000] 0% Loss:0.6150\n",
      "Epoch:38 [6400/25000] 26% Loss:0.6301\n",
      "Epoch:38 [12800/25000] 51% Loss:0.6755\n",
      "Epoch:38 [19200/25000] 77% Loss:0.7053\n",
      "\n",
      "Test Error:0.0087 Correct:19726 Accuracy:78.9040\n",
      "Epoch:39 [0/25000] 0% Loss:0.4777\n",
      "Epoch:39 [6400/25000] 26% Loss:0.6097\n",
      "Epoch:39 [12800/25000] 51% Loss:0.7020\n",
      "Epoch:39 [19200/25000] 77% Loss:0.5189\n",
      "\n",
      "Test Error:0.0086 Correct:19778 Accuracy:79.1120\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,40):\n",
    "  #print(torch.cuda.is_available())\n",
    "    train(i)\n",
    "    test()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_creator():\n",
    "    device='cuda:0'\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    matrix = np.zeros((5,5))\n",
    "    for inputs,targets in testsetLoader:\n",
    "        inputs = Variable(inputs)\n",
    "        inputs = inputs.to(device)\n",
    "        targets = Variable(targets)\n",
    "        targets = targets.to(device)\n",
    "        preds = model(inputs)\n",
    "        \n",
    "        label = torch.max(preds,1)[1]\n",
    "        l = list(targets.shape)\n",
    "        \n",
    "        i = 0\n",
    "        while i < l[0]:\n",
    "            matrix[targets[i]][label[i]] += 1 \n",
    "            #print(matrix)\n",
    "            i = i+1\n",
    "    print(matrix)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4184.  272.  298.  147.   99.]\n",
      " [ 144. 4736.   34.   66.   20.]\n",
      " [ 405.   92. 3417.  599.  487.]\n",
      " [ 217.  105.  489. 3805.  384.]\n",
      " [ 206.   57.  550.  551. 3636.]]\n"
     ]
    }
   ],
   "source": [
    "conf_creator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
