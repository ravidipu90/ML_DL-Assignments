{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Function to unpack the cifar-10 dataset.\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as file:\n",
    "        data = pickle.load(file, encoding='bytes')\n",
    "    return data[b'data'], data[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "#from utils import unpickle\n",
    "\n",
    "\n",
    "class LoadTrainingData(Dataset):\n",
    "    def __init__(self):\n",
    "        self.trainX = []\n",
    "        self.trainY = []\n",
    "\n",
    "        data_dir = './cifar-10/training batches'\n",
    "        batches = os.listdir(data_dir)\n",
    "\n",
    "        for batch in batches:\n",
    "            batch_data, batch_labels = unpickle(os.path.join(data_dir, batch))\n",
    "            self.trainX.extend(batch_data)\n",
    "            self.trainY.extend(batch_labels)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.trainX[item], self.trainY[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchvision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-18a8aa7782c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m ])\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = './cifar-10/'\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Normalize the test set same as training set without augmentation\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=opt.batch_size_train, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=opt.batch_size_test, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.layers = nn.Sequential(OrderedDict([\n",
    "            ('layer1', nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(num_features=32),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )),\n",
    "            ('layer2', nn.Sequential(\n",
    "                nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(num_features=64),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )),\n",
    "            ('fc1', nn.Sequential(\n",
    "                nn.Linear(in_features=8 * 8 * 64, out_features=1024),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "        ]))\n",
    "        self.out = nn.Linear(in_features=1024, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for name, module in self.layers.named_children():\n",
    "            x = module(x)\n",
    "\n",
    "            if name == 'layer2':\n",
    "                x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.out(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH: 1, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 2.301567]\n",
      "-[step: 2, loss: 2.292770]\n",
      "-[step: 3, loss: 2.276508]\n",
      "-[step: 4, loss: 2.257814]\n",
      "-[step: 5, loss: 2.233335]\n",
      "-[step: 6, loss: 2.209933]\n",
      "-[step: 7, loss: 2.192120]\n",
      "-[step: 8, loss: 2.152890]\n",
      "-[step: 9, loss: 2.165091]\n",
      "-[step: 10, loss: 2.145174]\n",
      "-[step: 11, loss: 2.115953]\n",
      "-[step: 12, loss: 2.115658]\n",
      "-[step: 13, loss: 2.090153]\n",
      "-[step: 14, loss: 2.115158]\n",
      "-[step: 15, loss: 2.091876]\n",
      "-[step: 16, loss: 2.054836]\n",
      "-[step: 17, loss: 2.062256]\n",
      "-[step: 18, loss: 2.061877]\n",
      "-[step: 19, loss: 2.056669]\n",
      "-[step: 20, loss: 2.013210]\n",
      "-[step: 21, loss: 2.025482]\n",
      "-[step: 22, loss: 2.030421]\n",
      "-[step: 23, loss: 2.026195]\n",
      "-[step: 24, loss: 1.997824]\n",
      "-[step: 25, loss: 1.997454]\n",
      "[EPOCH: 2, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.981152]\n",
      "-[step: 2, loss: 1.975069]\n",
      "-[step: 3, loss: 1.974908]\n",
      "-[step: 4, loss: 1.985329]\n",
      "-[step: 5, loss: 1.981535]\n",
      "-[step: 6, loss: 1.974297]\n",
      "-[step: 7, loss: 1.944162]\n",
      "-[step: 8, loss: 1.962361]\n",
      "-[step: 9, loss: 1.957241]\n",
      "-[step: 10, loss: 1.945187]\n",
      "-[step: 11, loss: 1.949943]\n",
      "-[step: 12, loss: 1.938827]\n",
      "-[step: 13, loss: 1.939860]\n",
      "-[step: 14, loss: 1.940665]\n",
      "-[step: 15, loss: 1.948618]\n",
      "-[step: 16, loss: 1.934571]\n",
      "-[step: 17, loss: 1.928959]\n",
      "-[step: 18, loss: 1.939313]\n",
      "-[step: 19, loss: 1.907411]\n",
      "-[step: 20, loss: 1.933082]\n",
      "-[step: 21, loss: 1.933361]\n",
      "-[step: 22, loss: 1.912781]\n",
      "-[step: 23, loss: 1.909217]\n",
      "-[step: 24, loss: 1.932764]\n",
      "-[step: 25, loss: 1.912026]\n",
      "[EPOCH: 3, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.891781]\n",
      "-[step: 2, loss: 1.897802]\n",
      "-[step: 3, loss: 1.900654]\n",
      "-[step: 4, loss: 1.889651]\n",
      "-[step: 5, loss: 1.891333]\n",
      "-[step: 6, loss: 1.882209]\n",
      "-[step: 7, loss: 1.887677]\n",
      "-[step: 8, loss: 1.885264]\n",
      "-[step: 9, loss: 1.880711]\n",
      "-[step: 10, loss: 1.898800]\n",
      "-[step: 11, loss: 1.886710]\n",
      "-[step: 12, loss: 1.898869]\n",
      "-[step: 13, loss: 1.884982]\n",
      "-[step: 14, loss: 1.873207]\n",
      "-[step: 15, loss: 1.861298]\n",
      "-[step: 16, loss: 1.866163]\n",
      "-[step: 17, loss: 1.870727]\n",
      "-[step: 18, loss: 1.876978]\n",
      "-[step: 19, loss: 1.872105]\n",
      "-[step: 20, loss: 1.871742]\n",
      "-[step: 21, loss: 1.861389]\n",
      "-[step: 22, loss: 1.854432]\n",
      "-[step: 23, loss: 1.854420]\n",
      "-[step: 24, loss: 1.849551]\n",
      "-[step: 25, loss: 1.858960]\n",
      "[EPOCH: 4, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.826814]\n",
      "-[step: 2, loss: 1.816306]\n",
      "-[step: 3, loss: 1.850301]\n",
      "-[step: 4, loss: 1.837088]\n",
      "-[step: 5, loss: 1.821720]\n",
      "-[step: 6, loss: 1.840855]\n",
      "-[step: 7, loss: 1.833235]\n",
      "-[step: 8, loss: 1.840717]\n",
      "-[step: 9, loss: 1.839116]\n",
      "-[step: 10, loss: 1.818411]\n",
      "-[step: 11, loss: 1.827687]\n",
      "-[step: 12, loss: 1.829914]\n",
      "-[step: 13, loss: 1.807789]\n",
      "-[step: 14, loss: 1.818550]\n",
      "-[step: 15, loss: 1.824778]\n",
      "-[step: 16, loss: 1.790489]\n",
      "-[step: 17, loss: 1.798994]\n",
      "-[step: 18, loss: 1.817723]\n",
      "-[step: 19, loss: 1.803903]\n",
      "-[step: 20, loss: 1.805343]\n",
      "-[step: 21, loss: 1.801245]\n",
      "-[step: 22, loss: 1.826642]\n",
      "-[step: 23, loss: 1.829316]\n",
      "-[step: 24, loss: 1.829622]\n",
      "-[step: 25, loss: 1.799740]\n",
      "[EPOCH: 5, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.788893]\n",
      "-[step: 2, loss: 1.804121]\n",
      "-[step: 3, loss: 1.790287]\n",
      "-[step: 4, loss: 1.781382]\n",
      "-[step: 5, loss: 1.784290]\n",
      "-[step: 6, loss: 1.755449]\n",
      "-[step: 7, loss: 1.788631]\n",
      "-[step: 8, loss: 1.786617]\n",
      "-[step: 9, loss: 1.784714]\n",
      "-[step: 10, loss: 1.786840]\n",
      "-[step: 11, loss: 1.786563]\n",
      "-[step: 12, loss: 1.793362]\n",
      "-[step: 13, loss: 1.778266]\n",
      "-[step: 14, loss: 1.759573]\n",
      "-[step: 15, loss: 1.772033]\n",
      "-[step: 16, loss: 1.770952]\n",
      "-[step: 17, loss: 1.781346]\n",
      "-[step: 18, loss: 1.771998]\n",
      "-[step: 19, loss: 1.783460]\n",
      "-[step: 20, loss: 1.761169]\n",
      "-[step: 21, loss: 1.762428]\n",
      "-[step: 22, loss: 1.776225]\n",
      "-[step: 23, loss: 1.787615]\n",
      "-[step: 24, loss: 1.762459]\n",
      "-[step: 25, loss: 1.774884]\n",
      "[EPOCH: 6, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.750785]\n",
      "-[step: 2, loss: 1.741571]\n",
      "-[step: 3, loss: 1.751569]\n",
      "-[step: 4, loss: 1.746770]\n",
      "-[step: 5, loss: 1.744454]\n",
      "-[step: 6, loss: 1.769408]\n",
      "-[step: 7, loss: 1.746464]\n",
      "-[step: 8, loss: 1.726075]\n",
      "-[step: 9, loss: 1.743347]\n",
      "-[step: 10, loss: 1.757479]\n",
      "-[step: 11, loss: 1.741978]\n",
      "-[step: 12, loss: 1.749730]\n",
      "-[step: 13, loss: 1.738384]\n",
      "-[step: 14, loss: 1.737065]\n",
      "-[step: 15, loss: 1.753176]\n",
      "-[step: 16, loss: 1.752108]\n",
      "-[step: 17, loss: 1.737550]\n",
      "-[step: 18, loss: 1.737879]\n",
      "-[step: 19, loss: 1.751518]\n",
      "-[step: 20, loss: 1.740781]\n",
      "-[step: 21, loss: 1.748425]\n",
      "-[step: 22, loss: 1.733080]\n",
      "-[step: 23, loss: 1.723422]\n",
      "-[step: 24, loss: 1.742601]\n",
      "-[step: 25, loss: 1.742364]\n",
      "[EPOCH: 7, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.727307]\n",
      "-[step: 2, loss: 1.727528]\n",
      "-[step: 3, loss: 1.705199]\n",
      "-[step: 4, loss: 1.714119]\n",
      "-[step: 5, loss: 1.732056]\n",
      "-[step: 6, loss: 1.720555]\n",
      "-[step: 7, loss: 1.716029]\n",
      "-[step: 8, loss: 1.726600]\n",
      "-[step: 9, loss: 1.729026]\n",
      "-[step: 10, loss: 1.716410]\n",
      "-[step: 11, loss: 1.704011]\n",
      "-[step: 12, loss: 1.705078]\n",
      "-[step: 13, loss: 1.721280]\n",
      "-[step: 14, loss: 1.716205]\n",
      "-[step: 15, loss: 1.705448]\n",
      "-[step: 16, loss: 1.708315]\n",
      "-[step: 17, loss: 1.705645]\n",
      "-[step: 18, loss: 1.709020]\n",
      "-[step: 19, loss: 1.719869]\n",
      "-[step: 20, loss: 1.726550]\n",
      "-[step: 21, loss: 1.721943]\n",
      "-[step: 22, loss: 1.710291]\n",
      "-[step: 23, loss: 1.707686]\n",
      "-[step: 24, loss: 1.721275]\n",
      "-[step: 25, loss: 1.717112]\n",
      "[EPOCH: 8, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.699781]\n",
      "-[step: 2, loss: 1.690252]\n",
      "-[step: 3, loss: 1.683210]\n",
      "-[step: 4, loss: 1.689188]\n",
      "-[step: 5, loss: 1.682244]\n",
      "-[step: 6, loss: 1.677516]\n",
      "-[step: 7, loss: 1.687058]\n",
      "-[step: 8, loss: 1.701794]\n",
      "-[step: 9, loss: 1.675362]\n",
      "-[step: 10, loss: 1.675332]\n",
      "-[step: 11, loss: 1.678709]\n",
      "-[step: 12, loss: 1.683310]\n",
      "-[step: 13, loss: 1.683692]\n",
      "-[step: 14, loss: 1.704677]\n",
      "-[step: 15, loss: 1.698056]\n",
      "-[step: 16, loss: 1.673857]\n",
      "-[step: 17, loss: 1.693136]\n",
      "-[step: 18, loss: 1.691423]\n",
      "-[step: 19, loss: 1.700727]\n",
      "-[step: 20, loss: 1.708188]\n",
      "-[step: 21, loss: 1.680834]\n",
      "-[step: 22, loss: 1.684262]\n",
      "-[step: 23, loss: 1.692391]\n",
      "-[step: 24, loss: 1.683046]\n",
      "-[step: 25, loss: 1.682102]\n",
      "[EPOCH: 9, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.659508]\n",
      "-[step: 2, loss: 1.665296]\n",
      "-[step: 3, loss: 1.691125]\n",
      "-[step: 4, loss: 1.655675]\n",
      "-[step: 5, loss: 1.671146]\n",
      "-[step: 6, loss: 1.658660]\n",
      "-[step: 7, loss: 1.656201]\n",
      "-[step: 8, loss: 1.667053]\n",
      "-[step: 9, loss: 1.672167]\n",
      "-[step: 10, loss: 1.667311]\n",
      "-[step: 11, loss: 1.663228]\n",
      "-[step: 12, loss: 1.648726]\n",
      "-[step: 13, loss: 1.646762]\n",
      "-[step: 14, loss: 1.645716]\n",
      "-[step: 15, loss: 1.670198]\n",
      "-[step: 16, loss: 1.670279]\n",
      "-[step: 17, loss: 1.660744]\n",
      "-[step: 18, loss: 1.668242]\n",
      "-[step: 19, loss: 1.675360]\n",
      "-[step: 20, loss: 1.687940]\n",
      "-[step: 21, loss: 1.685512]\n",
      "-[step: 22, loss: 1.667722]\n",
      "-[step: 23, loss: 1.674209]\n",
      "-[step: 24, loss: 1.681837]\n",
      "-[step: 25, loss: 1.687874]\n",
      "[EPOCH: 10, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.652547]\n",
      "-[step: 2, loss: 1.658504]\n",
      "-[step: 3, loss: 1.645637]\n",
      "-[step: 4, loss: 1.640865]\n",
      "-[step: 5, loss: 1.645349]\n",
      "-[step: 6, loss: 1.660793]\n",
      "-[step: 7, loss: 1.640586]\n",
      "-[step: 8, loss: 1.640942]\n",
      "-[step: 9, loss: 1.649248]\n",
      "-[step: 10, loss: 1.637642]\n",
      "-[step: 11, loss: 1.646502]\n",
      "-[step: 12, loss: 1.654419]\n",
      "-[step: 13, loss: 1.630500]\n",
      "-[step: 14, loss: 1.650764]\n",
      "-[step: 15, loss: 1.633839]\n",
      "-[step: 16, loss: 1.647295]\n",
      "-[step: 17, loss: 1.651606]\n",
      "-[step: 18, loss: 1.656406]\n",
      "-[step: 19, loss: 1.650941]\n",
      "-[step: 20, loss: 1.651859]\n",
      "-[step: 21, loss: 1.648576]\n",
      "-[step: 22, loss: 1.643937]\n",
      "-[step: 23, loss: 1.638215]\n",
      "-[step: 24, loss: 1.650060]\n",
      "-[step: 25, loss: 1.654637]\n",
      "[EPOCH: 11, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.622559]\n",
      "-[step: 2, loss: 1.627679]\n",
      "-[step: 3, loss: 1.622280]\n",
      "-[step: 4, loss: 1.641466]\n",
      "-[step: 5, loss: 1.612405]\n",
      "-[step: 6, loss: 1.622566]\n",
      "-[step: 7, loss: 1.626190]\n",
      "-[step: 8, loss: 1.629928]\n",
      "-[step: 9, loss: 1.627981]\n",
      "-[step: 10, loss: 1.612655]\n",
      "-[step: 11, loss: 1.635139]\n",
      "-[step: 12, loss: 1.608542]\n",
      "-[step: 13, loss: 1.607254]\n",
      "-[step: 14, loss: 1.635219]\n",
      "-[step: 15, loss: 1.625687]\n",
      "-[step: 16, loss: 1.630764]\n",
      "-[step: 17, loss: 1.634057]\n",
      "-[step: 18, loss: 1.605535]\n",
      "-[step: 19, loss: 1.613832]\n",
      "-[step: 20, loss: 1.611653]\n",
      "-[step: 21, loss: 1.621834]\n",
      "-[step: 22, loss: 1.627832]\n",
      "-[step: 23, loss: 1.619059]\n",
      "-[step: 24, loss: 1.635616]\n",
      "-[step: 25, loss: 1.649783]\n",
      "[EPOCH: 12, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.607975]\n",
      "-[step: 2, loss: 1.611360]\n",
      "-[step: 3, loss: 1.612995]\n",
      "-[step: 4, loss: 1.598031]\n",
      "-[step: 5, loss: 1.605770]\n",
      "-[step: 6, loss: 1.596987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-[step: 7, loss: 1.608867]\n",
      "-[step: 8, loss: 1.586722]\n",
      "-[step: 9, loss: 1.601051]\n",
      "-[step: 10, loss: 1.607148]\n",
      "-[step: 11, loss: 1.596421]\n",
      "-[step: 12, loss: 1.599518]\n",
      "-[step: 13, loss: 1.601556]\n",
      "-[step: 14, loss: 1.596440]\n",
      "-[step: 15, loss: 1.596069]\n",
      "-[step: 16, loss: 1.599000]\n",
      "-[step: 17, loss: 1.611371]\n",
      "-[step: 18, loss: 1.601018]\n",
      "-[step: 19, loss: 1.603964]\n",
      "-[step: 20, loss: 1.608648]\n",
      "-[step: 21, loss: 1.604140]\n",
      "-[step: 22, loss: 1.606848]\n",
      "-[step: 23, loss: 1.597360]\n",
      "-[step: 24, loss: 1.603546]\n",
      "-[step: 25, loss: 1.602724]\n",
      "[EPOCH: 13, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.592598]\n",
      "-[step: 2, loss: 1.584652]\n",
      "-[step: 3, loss: 1.586247]\n",
      "-[step: 4, loss: 1.586319]\n",
      "-[step: 5, loss: 1.571583]\n",
      "-[step: 6, loss: 1.582771]\n",
      "-[step: 7, loss: 1.576900]\n",
      "-[step: 8, loss: 1.582707]\n",
      "-[step: 9, loss: 1.583273]\n",
      "-[step: 10, loss: 1.580014]\n",
      "-[step: 11, loss: 1.576215]\n",
      "-[step: 12, loss: 1.578402]\n",
      "-[step: 13, loss: 1.574401]\n",
      "-[step: 14, loss: 1.589114]\n",
      "-[step: 15, loss: 1.585638]\n",
      "-[step: 16, loss: 1.599082]\n",
      "-[step: 17, loss: 1.584869]\n",
      "-[step: 18, loss: 1.581299]\n",
      "-[step: 19, loss: 1.598101]\n",
      "-[step: 20, loss: 1.598507]\n",
      "-[step: 21, loss: 1.591316]\n",
      "-[step: 22, loss: 1.568348]\n",
      "-[step: 23, loss: 1.591780]\n",
      "-[step: 24, loss: 1.575449]\n",
      "-[step: 25, loss: 1.586623]\n",
      "[EPOCH: 14, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.584194]\n",
      "-[step: 2, loss: 1.566800]\n",
      "-[step: 3, loss: 1.574512]\n",
      "-[step: 4, loss: 1.581428]\n",
      "-[step: 5, loss: 1.575456]\n",
      "-[step: 6, loss: 1.569269]\n",
      "-[step: 7, loss: 1.567991]\n",
      "-[step: 8, loss: 1.579872]\n",
      "-[step: 9, loss: 1.585270]\n",
      "-[step: 10, loss: 1.568197]\n",
      "-[step: 11, loss: 1.579278]\n",
      "-[step: 12, loss: 1.580304]\n",
      "-[step: 13, loss: 1.585578]\n",
      "-[step: 14, loss: 1.571261]\n",
      "-[step: 15, loss: 1.572540]\n",
      "-[step: 16, loss: 1.568044]\n",
      "-[step: 17, loss: 1.561615]\n",
      "-[step: 18, loss: 1.566266]\n",
      "-[step: 19, loss: 1.582282]\n",
      "-[step: 20, loss: 1.574804]\n",
      "-[step: 21, loss: 1.574341]\n",
      "-[step: 22, loss: 1.570921]\n",
      "-[step: 23, loss: 1.568024]\n",
      "-[step: 24, loss: 1.579504]\n",
      "-[step: 25, loss: 1.566176]\n",
      "[EPOCH: 15, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.553014]\n",
      "-[step: 2, loss: 1.564993]\n",
      "-[step: 3, loss: 1.570655]\n",
      "-[step: 4, loss: 1.573683]\n",
      "-[step: 5, loss: 1.556335]\n",
      "-[step: 6, loss: 1.575113]\n",
      "-[step: 7, loss: 1.569436]\n",
      "-[step: 8, loss: 1.553347]\n",
      "-[step: 9, loss: 1.550453]\n",
      "-[step: 10, loss: 1.548695]\n",
      "-[step: 11, loss: 1.567722]\n",
      "-[step: 12, loss: 1.560830]\n",
      "-[step: 13, loss: 1.559892]\n",
      "-[step: 14, loss: 1.564829]\n",
      "-[step: 15, loss: 1.555133]\n",
      "-[step: 16, loss: 1.559095]\n",
      "-[step: 17, loss: 1.559415]\n",
      "-[step: 18, loss: 1.565224]\n",
      "-[step: 19, loss: 1.561863]\n",
      "-[step: 20, loss: 1.562940]\n",
      "-[step: 21, loss: 1.555704]\n",
      "-[step: 22, loss: 1.568957]\n",
      "-[step: 23, loss: 1.556734]\n",
      "-[step: 24, loss: 1.558604]\n",
      "-[step: 25, loss: 1.570667]\n",
      "[EPOCH: 16, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.553723]\n",
      "-[step: 2, loss: 1.557936]\n",
      "-[step: 3, loss: 1.552349]\n",
      "-[step: 4, loss: 1.554062]\n",
      "-[step: 5, loss: 1.544379]\n",
      "-[step: 6, loss: 1.547988]\n",
      "-[step: 7, loss: 1.548463]\n",
      "-[step: 8, loss: 1.546074]\n",
      "-[step: 9, loss: 1.550557]\n",
      "-[step: 10, loss: 1.549873]\n",
      "-[step: 11, loss: 1.547287]\n",
      "-[step: 12, loss: 1.553140]\n",
      "-[step: 13, loss: 1.553120]\n",
      "-[step: 14, loss: 1.559043]\n",
      "-[step: 15, loss: 1.571869]\n",
      "-[step: 16, loss: 1.556025]\n",
      "-[step: 17, loss: 1.550401]\n",
      "-[step: 18, loss: 1.555995]\n",
      "-[step: 19, loss: 1.553975]\n",
      "-[step: 20, loss: 1.557889]\n",
      "-[step: 21, loss: 1.549571]\n",
      "-[step: 22, loss: 1.550966]\n",
      "-[step: 23, loss: 1.552046]\n",
      "-[step: 24, loss: 1.552349]\n",
      "-[step: 25, loss: 1.545134]\n",
      "[EPOCH: 17, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.544417]\n",
      "-[step: 2, loss: 1.547040]\n",
      "-[step: 3, loss: 1.551326]\n",
      "-[step: 4, loss: 1.545233]\n",
      "-[step: 5, loss: 1.542411]\n",
      "-[step: 6, loss: 1.547209]\n",
      "-[step: 7, loss: 1.552658]\n",
      "-[step: 8, loss: 1.535264]\n",
      "-[step: 9, loss: 1.539933]\n",
      "-[step: 10, loss: 1.546601]\n",
      "-[step: 11, loss: 1.545018]\n",
      "-[step: 12, loss: 1.541944]\n",
      "-[step: 13, loss: 1.544035]\n",
      "-[step: 14, loss: 1.536531]\n",
      "-[step: 15, loss: 1.548376]\n",
      "-[step: 16, loss: 1.537049]\n",
      "-[step: 17, loss: 1.552458]\n",
      "-[step: 18, loss: 1.536813]\n",
      "-[step: 19, loss: 1.541909]\n",
      "-[step: 20, loss: 1.545953]\n",
      "-[step: 21, loss: 1.548971]\n",
      "-[step: 22, loss: 1.543577]\n",
      "-[step: 23, loss: 1.556965]\n",
      "-[step: 24, loss: 1.547738]\n",
      "-[step: 25, loss: 1.540381]\n",
      "[EPOCH: 18, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.541651]\n",
      "-[step: 2, loss: 1.539943]\n",
      "-[step: 3, loss: 1.544600]\n",
      "-[step: 4, loss: 1.540811]\n",
      "-[step: 5, loss: 1.530508]\n",
      "-[step: 6, loss: 1.539727]\n",
      "-[step: 7, loss: 1.529791]\n",
      "-[step: 8, loss: 1.533513]\n",
      "-[step: 9, loss: 1.551705]\n",
      "-[step: 10, loss: 1.537247]\n",
      "-[step: 11, loss: 1.547165]\n",
      "-[step: 12, loss: 1.536035]\n",
      "-[step: 13, loss: 1.534556]\n",
      "-[step: 14, loss: 1.533006]\n",
      "-[step: 15, loss: 1.534833]\n",
      "-[step: 16, loss: 1.528930]\n",
      "-[step: 17, loss: 1.529257]\n",
      "-[step: 18, loss: 1.542550]\n",
      "-[step: 19, loss: 1.553379]\n",
      "-[step: 20, loss: 1.525175]\n",
      "-[step: 21, loss: 1.529503]\n",
      "-[step: 22, loss: 1.544164]\n",
      "-[step: 23, loss: 1.541972]\n",
      "-[step: 24, loss: 1.544494]\n",
      "-[step: 25, loss: 1.543664]\n",
      "[EPOCH: 19, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.535572]\n",
      "-[step: 2, loss: 1.539410]\n",
      "-[step: 3, loss: 1.530043]\n",
      "-[step: 4, loss: 1.542037]\n",
      "-[step: 5, loss: 1.530911]\n",
      "-[step: 6, loss: 1.533905]\n",
      "-[step: 7, loss: 1.541009]\n",
      "-[step: 8, loss: 1.535230]\n",
      "-[step: 9, loss: 1.542570]\n",
      "-[step: 10, loss: 1.539718]\n",
      "-[step: 11, loss: 1.526774]\n",
      "-[step: 12, loss: 1.532986]\n",
      "-[step: 13, loss: 1.531044]\n",
      "-[step: 14, loss: 1.535947]\n",
      "-[step: 15, loss: 1.535438]\n",
      "-[step: 16, loss: 1.536064]\n",
      "-[step: 17, loss: 1.521346]\n",
      "-[step: 18, loss: 1.548558]\n",
      "-[step: 19, loss: 1.531972]\n",
      "-[step: 20, loss: 1.527036]\n",
      "-[step: 21, loss: 1.535383]\n",
      "-[step: 22, loss: 1.527594]\n",
      "-[step: 23, loss: 1.527468]\n",
      "-[step: 24, loss: 1.529912]\n",
      "-[step: 25, loss: 1.536532]\n",
      "[EPOCH: 20, Learning Rate: 0.200000]\n",
      "\n",
      "-[step: 1, loss: 1.529275]\n",
      "-[step: 2, loss: 1.533067]\n",
      "-[step: 3, loss: 1.529298]\n",
      "-[step: 4, loss: 1.522091]\n",
      "-[step: 5, loss: 1.527403]\n",
      "-[step: 6, loss: 1.528909]\n",
      "-[step: 7, loss: 1.534766]\n",
      "-[step: 8, loss: 1.526774]\n",
      "-[step: 9, loss: 1.524809]\n",
      "-[step: 10, loss: 1.537586]\n",
      "-[step: 11, loss: 1.535088]\n",
      "-[step: 12, loss: 1.525339]\n",
      "-[step: 13, loss: 1.528911]\n",
      "-[step: 14, loss: 1.536431]\n",
      "-[step: 15, loss: 1.536378]\n",
      "-[step: 16, loss: 1.535886]\n",
      "-[step: 17, loss: 1.524534]\n",
      "-[step: 18, loss: 1.540822]\n",
      "-[step: 19, loss: 1.527329]\n",
      "-[step: 20, loss: 1.533718]\n",
      "-[step: 21, loss: 1.532347]\n",
      "-[step: 22, loss: 1.530377]\n",
      "-[step: 23, loss: 1.523249]\n",
      "-[step: 24, loss: 1.528519]\n",
      "-[step: 25, loss: 1.524395]\n",
      "[EPOCH: 21, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.528732]\n",
      "-[step: 2, loss: 1.533318]\n",
      "-[step: 3, loss: 1.530780]\n",
      "-[step: 4, loss: 1.529072]\n",
      "-[step: 5, loss: 1.533895]\n",
      "-[step: 6, loss: 1.523049]\n",
      "-[step: 7, loss: 1.524386]\n",
      "-[step: 8, loss: 1.521697]\n",
      "-[step: 9, loss: 1.530804]\n",
      "-[step: 10, loss: 1.528112]\n",
      "-[step: 11, loss: 1.517660]\n",
      "-[step: 12, loss: 1.528371]\n",
      "-[step: 13, loss: 1.527949]\n",
      "-[step: 14, loss: 1.528472]\n",
      "-[step: 15, loss: 1.521311]\n",
      "-[step: 16, loss: 1.529554]\n",
      "-[step: 17, loss: 1.522125]\n",
      "-[step: 18, loss: 1.523194]\n",
      "-[step: 19, loss: 1.523763]\n",
      "-[step: 20, loss: 1.529417]\n",
      "-[step: 21, loss: 1.521592]\n",
      "-[step: 22, loss: 1.526035]\n",
      "-[step: 23, loss: 1.521171]\n",
      "-[step: 24, loss: 1.530700]\n",
      "-[step: 25, loss: 1.541907]\n",
      "[EPOCH: 22, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.525113]\n",
      "-[step: 2, loss: 1.533139]\n",
      "-[step: 3, loss: 1.523335]\n",
      "-[step: 4, loss: 1.528191]\n",
      "-[step: 5, loss: 1.520370]\n",
      "-[step: 6, loss: 1.522101]\n",
      "-[step: 7, loss: 1.522597]\n",
      "-[step: 8, loss: 1.522692]\n",
      "-[step: 9, loss: 1.529508]\n",
      "-[step: 10, loss: 1.532574]\n",
      "-[step: 11, loss: 1.524794]\n",
      "-[step: 12, loss: 1.541060]\n",
      "-[step: 13, loss: 1.526370]\n",
      "-[step: 14, loss: 1.528585]\n",
      "-[step: 15, loss: 1.534662]\n",
      "-[step: 16, loss: 1.526087]\n",
      "-[step: 17, loss: 1.520126]\n",
      "-[step: 18, loss: 1.526032]\n",
      "-[step: 19, loss: 1.534159]\n",
      "-[step: 20, loss: 1.527874]\n",
      "-[step: 21, loss: 1.519378]\n",
      "-[step: 22, loss: 1.522982]\n",
      "-[step: 23, loss: 1.531145]\n",
      "-[step: 24, loss: 1.523348]\n",
      "-[step: 25, loss: 1.521524]\n",
      "[EPOCH: 23, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.521476]\n",
      "-[step: 2, loss: 1.526962]\n",
      "-[step: 3, loss: 1.523246]\n",
      "-[step: 4, loss: 1.530928]\n",
      "-[step: 5, loss: 1.533159]\n",
      "-[step: 6, loss: 1.541048]\n",
      "-[step: 7, loss: 1.526219]\n",
      "-[step: 8, loss: 1.532334]\n",
      "-[step: 9, loss: 1.523071]\n",
      "-[step: 10, loss: 1.528214]\n",
      "-[step: 11, loss: 1.536192]\n",
      "-[step: 12, loss: 1.530030]\n",
      "-[step: 13, loss: 1.522726]\n",
      "-[step: 14, loss: 1.517254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-[step: 15, loss: 1.525694]\n",
      "-[step: 16, loss: 1.526849]\n",
      "-[step: 17, loss: 1.525555]\n",
      "-[step: 18, loss: 1.521559]\n",
      "-[step: 19, loss: 1.527334]\n",
      "-[step: 20, loss: 1.526304]\n",
      "-[step: 21, loss: 1.515346]\n",
      "-[step: 22, loss: 1.525240]\n",
      "-[step: 23, loss: 1.518541]\n",
      "-[step: 24, loss: 1.521445]\n",
      "-[step: 25, loss: 1.535055]\n",
      "[EPOCH: 24, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.539808]\n",
      "-[step: 2, loss: 1.526635]\n",
      "-[step: 3, loss: 1.526001]\n",
      "-[step: 4, loss: 1.525193]\n",
      "-[step: 5, loss: 1.524613]\n",
      "-[step: 6, loss: 1.528049]\n",
      "-[step: 7, loss: 1.531738]\n",
      "-[step: 8, loss: 1.524133]\n",
      "-[step: 9, loss: 1.522188]\n",
      "-[step: 10, loss: 1.539484]\n",
      "-[step: 11, loss: 1.525808]\n",
      "-[step: 12, loss: 1.529989]\n",
      "-[step: 13, loss: 1.524159]\n",
      "-[step: 14, loss: 1.531269]\n",
      "-[step: 15, loss: 1.524484]\n",
      "-[step: 16, loss: 1.518479]\n",
      "-[step: 17, loss: 1.525067]\n",
      "-[step: 18, loss: 1.517382]\n",
      "-[step: 19, loss: 1.525409]\n",
      "-[step: 20, loss: 1.526881]\n",
      "-[step: 21, loss: 1.524439]\n",
      "-[step: 22, loss: 1.528955]\n",
      "-[step: 23, loss: 1.519753]\n",
      "-[step: 24, loss: 1.529255]\n",
      "-[step: 25, loss: 1.519907]\n",
      "[EPOCH: 25, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.532115]\n",
      "-[step: 2, loss: 1.523893]\n",
      "-[step: 3, loss: 1.518466]\n",
      "-[step: 4, loss: 1.532117]\n",
      "-[step: 5, loss: 1.526368]\n",
      "-[step: 6, loss: 1.524913]\n",
      "-[step: 7, loss: 1.524206]\n",
      "-[step: 8, loss: 1.528330]\n",
      "-[step: 9, loss: 1.528030]\n",
      "-[step: 10, loss: 1.520524]\n",
      "-[step: 11, loss: 1.521379]\n",
      "-[step: 12, loss: 1.527231]\n",
      "-[step: 13, loss: 1.532359]\n",
      "-[step: 14, loss: 1.520196]\n",
      "-[step: 15, loss: 1.536629]\n",
      "-[step: 16, loss: 1.523643]\n",
      "-[step: 17, loss: 1.533562]\n",
      "-[step: 18, loss: 1.525981]\n",
      "-[step: 19, loss: 1.520487]\n",
      "-[step: 20, loss: 1.523600]\n",
      "-[step: 21, loss: 1.532136]\n",
      "-[step: 22, loss: 1.525716]\n",
      "-[step: 23, loss: 1.527615]\n",
      "-[step: 24, loss: 1.521279]\n",
      "-[step: 25, loss: 1.525701]\n",
      "[EPOCH: 26, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.525752]\n",
      "-[step: 2, loss: 1.518366]\n",
      "-[step: 3, loss: 1.530134]\n",
      "-[step: 4, loss: 1.523263]\n",
      "-[step: 5, loss: 1.520520]\n",
      "-[step: 6, loss: 1.525113]\n",
      "-[step: 7, loss: 1.527882]\n",
      "-[step: 8, loss: 1.525267]\n",
      "-[step: 9, loss: 1.525478]\n",
      "-[step: 10, loss: 1.533393]\n",
      "-[step: 11, loss: 1.526906]\n",
      "-[step: 12, loss: 1.528458]\n",
      "-[step: 13, loss: 1.525516]\n",
      "-[step: 14, loss: 1.538797]\n",
      "-[step: 15, loss: 1.521266]\n",
      "-[step: 16, loss: 1.523849]\n",
      "-[step: 17, loss: 1.523510]\n",
      "-[step: 18, loss: 1.526064]\n",
      "-[step: 19, loss: 1.521243]\n",
      "-[step: 20, loss: 1.519344]\n",
      "-[step: 21, loss: 1.532934]\n",
      "-[step: 22, loss: 1.530217]\n",
      "-[step: 23, loss: 1.524607]\n",
      "-[step: 24, loss: 1.531733]\n",
      "-[step: 25, loss: 1.524543]\n",
      "[EPOCH: 27, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.515633]\n",
      "-[step: 2, loss: 1.529566]\n",
      "-[step: 3, loss: 1.527838]\n",
      "-[step: 4, loss: 1.521346]\n",
      "-[step: 5, loss: 1.537677]\n",
      "-[step: 6, loss: 1.521451]\n",
      "-[step: 7, loss: 1.527249]\n",
      "-[step: 8, loss: 1.529798]\n",
      "-[step: 9, loss: 1.524748]\n",
      "-[step: 10, loss: 1.525724]\n",
      "-[step: 11, loss: 1.522519]\n",
      "-[step: 12, loss: 1.527133]\n",
      "-[step: 13, loss: 1.531836]\n",
      "-[step: 14, loss: 1.530149]\n",
      "-[step: 15, loss: 1.517350]\n",
      "-[step: 16, loss: 1.529980]\n",
      "-[step: 17, loss: 1.526149]\n",
      "-[step: 18, loss: 1.536207]\n",
      "-[step: 19, loss: 1.517260]\n",
      "-[step: 20, loss: 1.520806]\n",
      "-[step: 21, loss: 1.522089]\n",
      "-[step: 22, loss: 1.519567]\n",
      "-[step: 23, loss: 1.533590]\n",
      "-[step: 24, loss: 1.529565]\n",
      "-[step: 25, loss: 1.526886]\n",
      "[EPOCH: 28, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.526985]\n",
      "-[step: 2, loss: 1.531356]\n",
      "-[step: 3, loss: 1.526173]\n",
      "-[step: 4, loss: 1.525085]\n",
      "-[step: 5, loss: 1.530442]\n",
      "-[step: 6, loss: 1.524814]\n",
      "-[step: 7, loss: 1.528238]\n",
      "-[step: 8, loss: 1.522232]\n",
      "-[step: 9, loss: 1.518176]\n",
      "-[step: 10, loss: 1.521326]\n",
      "-[step: 11, loss: 1.525830]\n",
      "-[step: 12, loss: 1.526341]\n",
      "-[step: 13, loss: 1.523152]\n",
      "-[step: 14, loss: 1.520280]\n",
      "-[step: 15, loss: 1.519196]\n",
      "-[step: 16, loss: 1.523626]\n",
      "-[step: 17, loss: 1.529626]\n",
      "-[step: 18, loss: 1.532999]\n",
      "-[step: 19, loss: 1.539023]\n",
      "-[step: 20, loss: 1.525992]\n",
      "-[step: 21, loss: 1.528910]\n",
      "-[step: 22, loss: 1.520783]\n",
      "-[step: 23, loss: 1.523447]\n",
      "-[step: 24, loss: 1.528851]\n",
      "-[step: 25, loss: 1.526966]\n",
      "[EPOCH: 29, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.521275]\n",
      "-[step: 2, loss: 1.523306]\n",
      "-[step: 3, loss: 1.528673]\n",
      "-[step: 4, loss: 1.536749]\n",
      "-[step: 5, loss: 1.525289]\n",
      "-[step: 6, loss: 1.520099]\n",
      "-[step: 7, loss: 1.517009]\n",
      "-[step: 8, loss: 1.511040]\n",
      "-[step: 9, loss: 1.516526]\n",
      "-[step: 10, loss: 1.529918]\n",
      "-[step: 11, loss: 1.530973]\n",
      "-[step: 12, loss: 1.524395]\n",
      "-[step: 13, loss: 1.525850]\n",
      "-[step: 14, loss: 1.530841]\n",
      "-[step: 15, loss: 1.520441]\n",
      "-[step: 16, loss: 1.525006]\n",
      "-[step: 17, loss: 1.525108]\n",
      "-[step: 18, loss: 1.528607]\n",
      "-[step: 19, loss: 1.522881]\n",
      "-[step: 20, loss: 1.527547]\n",
      "-[step: 21, loss: 1.533364]\n",
      "-[step: 22, loss: 1.528592]\n",
      "-[step: 23, loss: 1.530488]\n",
      "-[step: 24, loss: 1.536597]\n",
      "-[step: 25, loss: 1.526809]\n",
      "[EPOCH: 30, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.521463]\n",
      "-[step: 2, loss: 1.520019]\n",
      "-[step: 3, loss: 1.532280]\n",
      "-[step: 4, loss: 1.517094]\n",
      "-[step: 5, loss: 1.527575]\n",
      "-[step: 6, loss: 1.521316]\n",
      "-[step: 7, loss: 1.523937]\n",
      "-[step: 8, loss: 1.517723]\n",
      "-[step: 9, loss: 1.530662]\n",
      "-[step: 10, loss: 1.533472]\n",
      "-[step: 11, loss: 1.521841]\n",
      "-[step: 12, loss: 1.523636]\n",
      "-[step: 13, loss: 1.528780]\n",
      "-[step: 14, loss: 1.516408]\n",
      "-[step: 15, loss: 1.523733]\n",
      "-[step: 16, loss: 1.531133]\n",
      "-[step: 17, loss: 1.533525]\n",
      "-[step: 18, loss: 1.540389]\n",
      "-[step: 19, loss: 1.532204]\n",
      "-[step: 20, loss: 1.526877]\n",
      "-[step: 21, loss: 1.523113]\n",
      "-[step: 22, loss: 1.524183]\n",
      "-[step: 23, loss: 1.529654]\n",
      "-[step: 24, loss: 1.516393]\n",
      "-[step: 25, loss: 1.528278]\n",
      "[EPOCH: 31, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.528680]\n",
      "-[step: 2, loss: 1.523623]\n",
      "-[step: 3, loss: 1.515157]\n",
      "-[step: 4, loss: 1.525284]\n",
      "-[step: 5, loss: 1.522656]\n",
      "-[step: 6, loss: 1.531972]\n",
      "-[step: 7, loss: 1.522191]\n",
      "-[step: 8, loss: 1.530982]\n",
      "-[step: 9, loss: 1.523767]\n",
      "-[step: 10, loss: 1.526767]\n",
      "-[step: 11, loss: 1.525892]\n",
      "-[step: 12, loss: 1.523119]\n",
      "-[step: 13, loss: 1.528700]\n",
      "-[step: 14, loss: 1.528294]\n",
      "-[step: 15, loss: 1.526158]\n",
      "-[step: 16, loss: 1.527880]\n",
      "-[step: 17, loss: 1.525759]\n",
      "-[step: 18, loss: 1.531558]\n",
      "-[step: 19, loss: 1.525517]\n",
      "-[step: 20, loss: 1.530907]\n",
      "-[step: 21, loss: 1.519792]\n",
      "-[step: 22, loss: 1.522653]\n",
      "-[step: 23, loss: 1.533357]\n",
      "-[step: 24, loss: 1.521765]\n",
      "-[step: 25, loss: 1.521634]\n",
      "[EPOCH: 32, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.529019]\n",
      "-[step: 2, loss: 1.520066]\n",
      "-[step: 3, loss: 1.529355]\n",
      "-[step: 4, loss: 1.525963]\n",
      "-[step: 5, loss: 1.528542]\n",
      "-[step: 6, loss: 1.513941]\n",
      "-[step: 7, loss: 1.525697]\n",
      "-[step: 8, loss: 1.519888]\n",
      "-[step: 9, loss: 1.531888]\n",
      "-[step: 10, loss: 1.522223]\n",
      "-[step: 11, loss: 1.532776]\n",
      "-[step: 12, loss: 1.522925]\n",
      "-[step: 13, loss: 1.521387]\n",
      "-[step: 14, loss: 1.521147]\n",
      "-[step: 15, loss: 1.523433]\n",
      "-[step: 16, loss: 1.524992]\n",
      "-[step: 17, loss: 1.531461]\n",
      "-[step: 18, loss: 1.526432]\n",
      "-[step: 19, loss: 1.534275]\n",
      "-[step: 20, loss: 1.529746]\n",
      "-[step: 21, loss: 1.523833]\n",
      "-[step: 22, loss: 1.521264]\n",
      "-[step: 23, loss: 1.534091]\n",
      "-[step: 24, loss: 1.522935]\n",
      "-[step: 25, loss: 1.524846]\n",
      "[EPOCH: 33, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.534195]\n",
      "-[step: 2, loss: 1.532063]\n",
      "-[step: 3, loss: 1.526534]\n",
      "-[step: 4, loss: 1.526727]\n",
      "-[step: 5, loss: 1.529339]\n",
      "-[step: 6, loss: 1.528978]\n",
      "-[step: 7, loss: 1.524002]\n",
      "-[step: 8, loss: 1.525491]\n",
      "-[step: 9, loss: 1.520546]\n",
      "-[step: 10, loss: 1.518918]\n",
      "-[step: 11, loss: 1.526374]\n",
      "-[step: 12, loss: 1.524157]\n",
      "-[step: 13, loss: 1.528226]\n",
      "-[step: 14, loss: 1.521233]\n",
      "-[step: 15, loss: 1.522699]\n",
      "-[step: 16, loss: 1.529427]\n",
      "-[step: 17, loss: 1.530909]\n",
      "-[step: 18, loss: 1.519851]\n",
      "-[step: 19, loss: 1.524032]\n",
      "-[step: 20, loss: 1.520667]\n",
      "-[step: 21, loss: 1.523701]\n",
      "-[step: 22, loss: 1.529707]\n",
      "-[step: 23, loss: 1.532382]\n",
      "-[step: 24, loss: 1.524727]\n",
      "-[step: 25, loss: 1.514744]\n",
      "[EPOCH: 34, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.523777]\n",
      "-[step: 2, loss: 1.530139]\n",
      "-[step: 3, loss: 1.520478]\n",
      "-[step: 4, loss: 1.522372]\n",
      "-[step: 5, loss: 1.532577]\n",
      "-[step: 6, loss: 1.517298]\n",
      "-[step: 7, loss: 1.511585]\n",
      "-[step: 8, loss: 1.531533]\n",
      "-[step: 9, loss: 1.523070]\n",
      "-[step: 10, loss: 1.529980]\n",
      "-[step: 11, loss: 1.524315]\n",
      "-[step: 12, loss: 1.515006]\n",
      "-[step: 13, loss: 1.526700]\n",
      "-[step: 14, loss: 1.523074]\n",
      "-[step: 15, loss: 1.535981]\n",
      "-[step: 16, loss: 1.523729]\n",
      "-[step: 17, loss: 1.522216]\n",
      "-[step: 18, loss: 1.525230]\n",
      "-[step: 19, loss: 1.531916]\n",
      "-[step: 20, loss: 1.528657]\n",
      "-[step: 21, loss: 1.523583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-[step: 22, loss: 1.531090]\n",
      "-[step: 23, loss: 1.531733]\n",
      "-[step: 24, loss: 1.529702]\n",
      "-[step: 25, loss: 1.522178]\n",
      "[EPOCH: 35, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.524109]\n",
      "-[step: 2, loss: 1.521720]\n",
      "-[step: 3, loss: 1.529190]\n",
      "-[step: 4, loss: 1.525542]\n",
      "-[step: 5, loss: 1.541047]\n",
      "-[step: 6, loss: 1.530302]\n",
      "-[step: 7, loss: 1.514991]\n",
      "-[step: 8, loss: 1.519609]\n",
      "-[step: 9, loss: 1.529602]\n",
      "-[step: 10, loss: 1.525289]\n",
      "-[step: 11, loss: 1.525458]\n",
      "-[step: 12, loss: 1.528204]\n",
      "-[step: 13, loss: 1.522348]\n",
      "-[step: 14, loss: 1.514276]\n",
      "-[step: 15, loss: 1.522035]\n",
      "-[step: 16, loss: 1.525554]\n",
      "-[step: 17, loss: 1.527093]\n",
      "-[step: 18, loss: 1.524886]\n",
      "-[step: 19, loss: 1.522889]\n",
      "-[step: 20, loss: 1.533844]\n",
      "-[step: 21, loss: 1.525225]\n",
      "-[step: 22, loss: 1.519916]\n",
      "-[step: 23, loss: 1.527823]\n",
      "-[step: 24, loss: 1.524634]\n",
      "-[step: 25, loss: 1.530548]\n",
      "[EPOCH: 36, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.518864]\n",
      "-[step: 2, loss: 1.524131]\n",
      "-[step: 3, loss: 1.526880]\n",
      "-[step: 4, loss: 1.531890]\n",
      "-[step: 5, loss: 1.520856]\n",
      "-[step: 6, loss: 1.523884]\n",
      "-[step: 7, loss: 1.521741]\n",
      "-[step: 8, loss: 1.523589]\n",
      "-[step: 9, loss: 1.538725]\n",
      "-[step: 10, loss: 1.526738]\n",
      "-[step: 11, loss: 1.522148]\n",
      "-[step: 12, loss: 1.529837]\n",
      "-[step: 13, loss: 1.529101]\n",
      "-[step: 14, loss: 1.528314]\n",
      "-[step: 15, loss: 1.525176]\n",
      "-[step: 16, loss: 1.518931]\n",
      "-[step: 17, loss: 1.526055]\n",
      "-[step: 18, loss: 1.526058]\n",
      "-[step: 19, loss: 1.525826]\n",
      "-[step: 20, loss: 1.526821]\n",
      "-[step: 21, loss: 1.525842]\n",
      "-[step: 22, loss: 1.527689]\n",
      "-[step: 23, loss: 1.518108]\n",
      "-[step: 24, loss: 1.521596]\n",
      "-[step: 25, loss: 1.525947]\n",
      "[EPOCH: 37, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.522551]\n",
      "-[step: 2, loss: 1.517801]\n",
      "-[step: 3, loss: 1.531212]\n",
      "-[step: 4, loss: 1.530447]\n",
      "-[step: 5, loss: 1.518264]\n",
      "-[step: 6, loss: 1.526924]\n",
      "-[step: 7, loss: 1.521168]\n",
      "-[step: 8, loss: 1.524073]\n",
      "-[step: 9, loss: 1.529667]\n",
      "-[step: 10, loss: 1.522672]\n",
      "-[step: 11, loss: 1.525274]\n",
      "-[step: 12, loss: 1.530419]\n",
      "-[step: 13, loss: 1.521296]\n",
      "-[step: 14, loss: 1.526462]\n",
      "-[step: 15, loss: 1.527543]\n",
      "-[step: 16, loss: 1.525125]\n",
      "-[step: 17, loss: 1.522985]\n",
      "-[step: 18, loss: 1.525045]\n",
      "-[step: 19, loss: 1.524304]\n",
      "-[step: 20, loss: 1.531958]\n",
      "-[step: 21, loss: 1.521239]\n",
      "-[step: 22, loss: 1.534404]\n",
      "-[step: 23, loss: 1.528840]\n",
      "-[step: 24, loss: 1.518315]\n",
      "-[step: 25, loss: 1.524645]\n",
      "[EPOCH: 38, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.529039]\n",
      "-[step: 2, loss: 1.534926]\n",
      "-[step: 3, loss: 1.526245]\n",
      "-[step: 4, loss: 1.522902]\n",
      "-[step: 5, loss: 1.525230]\n",
      "-[step: 6, loss: 1.523726]\n",
      "-[step: 7, loss: 1.523186]\n",
      "-[step: 8, loss: 1.523939]\n",
      "-[step: 9, loss: 1.520910]\n",
      "-[step: 10, loss: 1.532392]\n",
      "-[step: 11, loss: 1.514641]\n",
      "-[step: 12, loss: 1.516176]\n",
      "-[step: 13, loss: 1.525057]\n",
      "-[step: 14, loss: 1.530663]\n",
      "-[step: 15, loss: 1.528697]\n",
      "-[step: 16, loss: 1.531539]\n",
      "-[step: 17, loss: 1.518691]\n",
      "-[step: 18, loss: 1.518743]\n",
      "-[step: 19, loss: 1.524301]\n",
      "-[step: 20, loss: 1.523299]\n",
      "-[step: 21, loss: 1.521865]\n",
      "-[step: 22, loss: 1.537628]\n",
      "-[step: 23, loss: 1.525917]\n",
      "-[step: 24, loss: 1.529958]\n",
      "-[step: 25, loss: 1.521103]\n",
      "[EPOCH: 39, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.529410]\n",
      "-[step: 2, loss: 1.520826]\n",
      "-[step: 3, loss: 1.535737]\n",
      "-[step: 4, loss: 1.524180]\n",
      "-[step: 5, loss: 1.529184]\n",
      "-[step: 6, loss: 1.527938]\n",
      "-[step: 7, loss: 1.533974]\n",
      "-[step: 8, loss: 1.532833]\n",
      "-[step: 9, loss: 1.528133]\n",
      "-[step: 10, loss: 1.530368]\n",
      "-[step: 11, loss: 1.518381]\n",
      "-[step: 12, loss: 1.519902]\n",
      "-[step: 13, loss: 1.520741]\n",
      "-[step: 14, loss: 1.528374]\n",
      "-[step: 15, loss: 1.533263]\n",
      "-[step: 16, loss: 1.521821]\n",
      "-[step: 17, loss: 1.524969]\n",
      "-[step: 18, loss: 1.519338]\n",
      "-[step: 19, loss: 1.531412]\n",
      "-[step: 20, loss: 1.520457]\n",
      "-[step: 21, loss: 1.521011]\n",
      "-[step: 22, loss: 1.522329]\n",
      "-[step: 23, loss: 1.518063]\n",
      "-[step: 24, loss: 1.516894]\n",
      "-[step: 25, loss: 1.519459]\n",
      "[EPOCH: 40, Learning Rate: 0.002000]\n",
      "\n",
      "-[step: 1, loss: 1.518215]\n",
      "-[step: 2, loss: 1.534664]\n",
      "-[step: 3, loss: 1.523432]\n",
      "-[step: 4, loss: 1.516037]\n",
      "-[step: 5, loss: 1.522376]\n",
      "-[step: 6, loss: 1.522657]\n",
      "-[step: 7, loss: 1.529051]\n",
      "-[step: 8, loss: 1.527161]\n",
      "-[step: 9, loss: 1.531335]\n",
      "-[step: 10, loss: 1.527022]\n",
      "-[step: 11, loss: 1.518749]\n",
      "-[step: 12, loss: 1.522701]\n",
      "-[step: 13, loss: 1.522183]\n",
      "-[step: 14, loss: 1.521848]\n",
      "-[step: 15, loss: 1.520740]\n",
      "-[step: 16, loss: 1.534286]\n",
      "-[step: 17, loss: 1.529745]\n",
      "-[step: 18, loss: 1.520960]\n",
      "-[step: 19, loss: 1.532913]\n",
      "-[step: 20, loss: 1.527358]\n",
      "-[step: 21, loss: 1.527367]\n",
      "-[step: 22, loss: 1.526506]\n",
      "-[step: 23, loss: 1.524904]\n",
      "-[step: 24, loss: 1.525749]\n",
      "-[step: 25, loss: 1.520489]\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from load_data import LoadTrainingData\n",
    "#from model import CNNModel\n",
    "\n",
    "def train_model(model, data, epoch, batch_size):\n",
    "    # define the loss function and back propagation algorithm\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.2, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.01)\n",
    "\n",
    "    for e in range(epoch):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            lr = param_group['lr']\n",
    "        print('[EPOCH: %d, Learning Rate: %f]' % (e+1, lr))\n",
    "        print()\n",
    "        for i, dataset in enumerate(data):\n",
    "            inputs, lbl = dataset\n",
    "            inputs, lbl = inputs.view(batch_size, 3, 32, 32).to('cuda', dtype=torch.float), lbl.view(-1).to('cuda')\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                inputs, lbl = inputs.cuda(), lbl.cuda()\n",
    "\n",
    "            # set the gradient for each parameters zero\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('-[step: %d, loss: %f]' % (i+1, loss.item()))\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "    print ('Finished Training')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cnn = CNNModel()\n",
    "    batch = 2000\n",
    "    if torch.cuda.is_available():\n",
    "        cnn.cuda()\n",
    "\n",
    "    trainingDataset = LoadTrainingData()\n",
    "    dataLoader = DataLoader(\n",
    "        dataset=trainingDataset,\n",
    "        batch_size=batch,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    train_model(cnn, dataLoader, epoch=40, batch_size=batch)\n",
    "\n",
    "    # save model\n",
    "    torch.save(cnn.state_dict(), './trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy...\n",
      "Accuracy:    76 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from utils import unpickle\n",
    "# from model import CNNModel\n",
    "\n",
    "def main():\n",
    "    trained_model = './trained_model.pth'\n",
    "    test_batch_dir = './cifar-10/test_batch'\n",
    "    \n",
    "    classifier = CNNModel()\n",
    "    classifier.load_state_dict(torch.load(trained_model))\n",
    "    classifier.cuda()\n",
    "    classifier.eval()\n",
    "\n",
    "    test_x, test_y = unpickle(test_batch_dir)\n",
    "    test_x, test_y = torch.tensor(np.reshape(test_x, (len(test_x), 3, 32, 32))).to('cuda', dtype=torch.float), torch.tensor(test_y).cuda()\n",
    "\n",
    "    classes = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "\n",
    "    # calculating the accuracy of our classifier;\n",
    "    print(\"Calculating accuracy...\")\n",
    "    correct = 0\n",
    "    total = len(test_x)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = classifier(test_x)\n",
    "        _, predicted = torch.max(out, 1)\n",
    "\n",
    "        # calculate the total accuracy\n",
    "        correct += (predicted == test_y).sum().item()\n",
    "        print('Accuracy: %5d %%' % (correct / total * 100))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
