{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os \n",
    "import torchvision\n",
    "import numpy \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from focal_loss.focal_loss import FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision.models import densenet121\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = 'tiny-imagenet-200/'\n",
    "num_workers = {\n",
    "    'train' : 100,\n",
    "    'val'   : 0,\n",
    "    'test'  : 0\n",
    "}\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val','test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=100,\n",
    "                                             shuffle=True, num_workers=num_workers[x])\n",
    "              for x in ['train', 'val', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Identity,self).__init__()\n",
    "\n",
    "  def forward(self,x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss1():\n",
    "    def _focal(y_true, y_pred):\n",
    "        \"\"\" Compute the focal loss given the target tensor and the predicted tensor.\n",
    "        As defined in https://arxiv.org/abs/1708.02002\n",
    "        Args\n",
    "            y_true: Tensor of target data from the generator with shape (B, N, num_classes).\n",
    "            y_pred: Tensor of predicted data from the network with shape (B, N, num_classes).\n",
    "        Returns\n",
    "            The focal loss of y_pred w.r.t. y_true.\n",
    "        \"\"\"\n",
    "        labels         = y_true[:, :, :-1]\n",
    "        anchor_state   = y_true[:, :, -1]  # -1 for ignore, 0 for background, 1 for object\n",
    "        classification = y_pred\n",
    "\n",
    "        # filter out \"ignore\" anchors\n",
    "        indices        = backend.where(keras.backend.not_equal(anchor_state, -1))\n",
    "        labels         = backend.gather_nd(labels, indices)\n",
    "        classification = backend.gather_nd(classification, indices)\n",
    "\n",
    "        # compute the focal loss\n",
    "        alpha_factor = keras.backend.ones_like(labels) * alpha\n",
    "        alpha_factor = backend.where(keras.backend.equal(labels, 1), alpha_factor, 1 - alpha_factor)\n",
    "        focal_weight = backend.where(keras.backend.equal(labels, 1), 1 - classification, classification)\n",
    "        focal_weight = backend.clip(focal_weight, backend.epsilon(), 1.0) # avoid NaN when net output is 1.0 or 0.0\n",
    "        focal_weight = alpha_factor * focal_weight ** gamma\n",
    "\n",
    "        cls_loss = focal_weight * keras.backend.binary_crossentropy(labels, classification)\n",
    "\n",
    "        # compute the normalizer: the number of positive anchors\n",
    "        normalizer = backend.where(keras.backend.equal(anchor_state, 1))\n",
    "        normalizer = keras.backend.cast(keras.backend.shape(normalizer)[0], keras.backend.floatx())\n",
    "        normalizer = keras.backend.maximum(keras.backend.cast_to_floatx(1.0), normalizer)\n",
    "\n",
    "        return keras.backend.sum(cls_loss) / normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = densenet121(pretrained=True)\n",
    "model_ft.fc = Identity()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "#Loss Function\n",
    "criterion = FocalLoss(alpha=2, gamma=10)\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch, time, copy, sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "def train_model(output_path, model, dataloaders, dataset_sizes, criterion, optimizer, num_epochs=5, scheduler=None):\n",
    "    if not os.path.exists('models/'+str(output_path)):\n",
    "        os.makedirs('models/'+str(output_path))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    since = time.time()\n",
    "    liveloss = PlotLosses()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                if scheduler != None:\n",
    "                    scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i,(inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                #print(inputs.size())\n",
    "                #print(labels.size())\n",
    "                \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    \n",
    "                    #labels.view(1,1000)\n",
    "                    #print(outputs.size())\n",
    "                    #print(labels.size())\n",
    "                    #break\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    labels = labels.view(100, 1)\n",
    "                    #loss = criterion._focal(outputs,labels)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                print(\"\\rIteration: {}/{}, Loss: {}.\".format(i+1, len(dataloaders[phase]), loss.item() * inputs.size(0)), end=\"\")\n",
    "\n",
    "#                 print( (i+1)*100. / len(dataloaders[phase]), \"% Complete\" )\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            if phase == 'train':\n",
    "                avg_loss = epoch_loss\n",
    "                t_acc = epoch_acc\n",
    "            else:\n",
    "                val_loss = epoch_loss\n",
    "                val_acc = epoch_acc\n",
    "            \n",
    "#             print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "#                 phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best = epoch + 1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        liveloss.update({\n",
    "            'log loss': avg_loss,\n",
    "            'val_log loss': val_loss,\n",
    "            'accuracy': t_acc,\n",
    "            'val_accuracy': val_acc\n",
    "        })\n",
    "                \n",
    "        liveloss.draw()\n",
    "        print('Train Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, t_acc))\n",
    "        print(  'Val Loss: {:.4f} Acc: {:.4f}'.format(val_loss, val_acc))\n",
    "        print()\n",
    "        torch.save(model.state_dict(), './models/' + str(output_path) + '/model_{}_epoch.pt'.format(epoch+1))\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best Validation Accuracy: {}, Epoch: {}'.format(best_acc, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan Acc: 0.5000\n",
      "Val Loss: nan Acc: 100.0000\n",
      "\n",
      "Training complete in 23m 56s\n",
      "Best Validation Accuracy: 100.0, Epoch: 1\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "train_model(\"DenseNet\",model_ft, dataloaders, dataset_sizes, criterion, optimizer_ft, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time, sys\n",
    "\n",
    "def test_model(model, dataloaders, dataset_sizes, criterion, optimizer):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    since = time.time()\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['test']:\n",
    "        model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for i,(inputs, labels) in enumerate(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels.view(100,1))\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            print(\"\\rIteration: {}/{}, Loss: {}.\".format(i+1, len(dataloaders[phase]), loss.item() * inputs.size(0)), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "    print()\n",
    "    print('Test Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "    print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Test complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100/100, Loss: nan.\n",
      "Test Loss: nan Acc: 1.0000\n",
      "\n",
      "Test complete in 0m 8s\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "test_model(model_ft, dataloaders, dataset_sizes, criterion, optimizer_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
