{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravidipu90/ML_DL-Assignments/blob/main/Bert_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KWmvP6rm0Py",
        "outputId": "a7454626-f4aa-45f4-f79c-2171165b3aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.23.5-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 55.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.64.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.2.0)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.5 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting botocore<1.27.0,>=1.26.5\n",
            "  Downloading botocore-1.26.5-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 59.5 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 73.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.27.0,>=1.26.5->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.0,>=1.26.5->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 75.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.23.5 botocore-1.26.5 jmespath-1.0.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.2 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMmcAQ4PwRG6",
        "outputId": "644d55a4-b8d3-47b5-927e-b6e12f6cab74"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check to confirm that GPU is available\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError ('GPU device not found')\n",
        "\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm , trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Dy3WYlmX8Dw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skqO12_hmzJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "kouQUz9B8WsO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4d039152-9518-49bd-c126-12797a2e7b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv ('train_data.csv', delimiter=',', header=None, names=['sentence', 'label'])\n",
        "df = df.drop(0)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "YcF6M5WE8lV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba31264-eaa4-4ba3-bad7-e0c7d78782c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19998, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "kEEw3cxHCW8I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8b06b3bb-fb6e-4d44-9817-797a1d09c36a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence label\n",
              "1    I am reading score of Mahler is Symphony No . .     0\n",
              "2  I am not interested in cars or electric applia...     1\n",
              "3         This is my homework for my English class .     0\n",
              "4  In comparison , Canada is catches increased an...     0\n",
              "5  Fortunately , my older sister is friend is a d...     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-376814b9-6a4e-4caa-954d-4118f4fdc08f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am reading score of Mahler is Symphony No . .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am not interested in cars or electric applia...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This is my homework for my English class .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In comparison , Canada is catches increased an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Fortunately , my older sister is friend is a d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-376814b9-6a4e-4caa-954d-4118f4fdc08f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-376814b9-6a4e-4caa-954d-4118f4fdc08f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-376814b9-6a4e-4caa-954d-4118f4fdc08f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = df.sentence.values\n",
        "sentences = [\"[CLS]\" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = df.label.values.astype(int)"
      ],
      "metadata": {
        "id": "Clj_ADNrGEDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
        "                                          do_lower_case = True)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print(\"Tokenize version of the the first sentence:\")\n",
        "print(tokenized_texts[0])"
      ],
      "metadata": {
        "id": "0wNpits-GO1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7591a0f9-06cd-4b6f-9de6-89906a22720a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 931786.71B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenize version of the the first sentence:\n",
            "['[', 'cl', '##s', ']', 'i', 'am', 'reading', 'score', 'of', 'ma', '##hler', 'is', 'symphony', 'no', '.', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding Sentences\n",
        "# Set the maximum sequence length. The longest sequence in our training set\n",
        "# is 47, but we'll leave room on the end anyway.\n",
        "# In the original paper, the authors used a length of 512.\n",
        "MAX_LEN = 256\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(\n",
        "    [tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "    maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\"\n",
        "    )\n",
        "\n",
        "# Index Numbers and Padding\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# pad sentences\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n",
        "                          dtype =\"long\", truncating=\"post\",padding =\"post\")"
      ],
      "metadata": {
        "id": "ptMyOzrLGgUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention masks\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i > 0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "metadata": {
        "id": "aVk4IGHzGirg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = \\\n",
        "  train_test_split(input_ids, labels, random_state=2018, test_size=0.2)\n",
        "\n",
        "train_masks, validation_masks , _, _ = \\\n",
        "  train_test_split(attention_masks, input_ids, random_state=2018, test_size=0.2)\n",
        "\n",
        "# transform all data into torch tensors\n",
        "train_inputs = torch.from_numpy(train_inputs)\n",
        "validation_inputs = torch.from_numpy(validation_inputs)\n",
        "train_labels = torch.from_numpy(train_labels)\n",
        "validation_labels = torch.from_numpy(validation_labels)\n",
        "train_masks = torch.from_numpy(np.array(train_masks))\n",
        "validation_masks = torch.from_numpy(np.array(validation_masks))"
      ],
      "metadata": {
        "id": "U29u7PHAGpMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparation for Training\n",
        "\n",
        "# Select a batch size for training. For fine tuning BERT on a\n",
        "# specific task , BERT authors recommend a batch size of 16 or 32\n",
        "batch_size = 16\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader\n",
        "# This helps save on memory during training because, unlike a for loop,\n",
        "# with iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = \\\n",
        "  DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = \\\n",
        "  TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = \\\n",
        "  DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "LdihJOGzQMpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels=3)\n",
        "\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "d_GylA0FQTYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eed19e6-79bb-4f95-ac42-eef4091790f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407873900/407873900 [00:12<00:00, 33366320.95B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.01\n",
        "    },\n",
        "    {\n",
        "        'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.00\n",
        "    }\n",
        "  ]\n",
        "\n",
        "optimizer = BertAdam(optimizer_grouped_parameters, lr=2e-6, warmup=0.1)"
      ],
      "metadata": {
        "id": "quQpn855Qls9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc2678c-9e50-4329-a4c4-a1f00af55c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculates the accuracy of our predictions vs labels\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "  pred_flat  = np.argmax(preds , axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat)/len(labels_flat)"
      ],
      "metadata": {
        "id": "Sp3Q6vnxQ050"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 6\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  # Training\n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask , b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids=None,\n",
        "                 attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "    train_loss_set.append(loss.item())\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "# Validation\n",
        "# Put model in evaluation mode to evaluate loss on the validation set\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in validation_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients,\n",
        "  # ve memory and speede up validation\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    logits = model(b_input_ids, token_type_ids =None, attention_mask=b_input_mask)\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "  eval_accuracy += tmp_eval_accuracy\n",
        "  nb_eval_steps += 1\n",
        "\n",
        "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "metadata": {
        "id": "if8NcNWvQ2sQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "004d1762-378b-4a6c-d25c-c648c6597016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  17%|█▋        | 1/6 [14:08<1:10:44, 848.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.6758443422913551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  33%|███▎      | 2/6 [28:17<56:34, 848.65s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.6263031465411186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 3/6 [42:26<42:26, 848.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.6036113116145134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 4/6 [56:34<28:17, 848.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.5864985023736954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  83%|████████▎ | 5/6 [1:10:43<14:08, 848.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.5673371410667897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 6/6 [1:24:52<00:00, 848.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.5569032430052757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "taBjTkB6U4Ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "ffbbbcd1-7c3a-4bb3-8e40-4ef4fccbd469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"val_data.csv\", delimiter=',', header=None,\n",
        "  names=['sentence', 'label'])\n",
        "df = df.drop(0)\n",
        "# Create sentence) and label lists\n",
        "sentences = df.sentence.values\n",
        "# We need to add special tokens at the beginning and end of each sentence\n",
        "# for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = df.label.values.astype(int)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "# Padding Sentences\n",
        "# Set the maximum sequence length. The longest sequence in our training set\n",
        "# is 47, but we'll leave room on the end anyway.\n",
        "# In the original paper, the authors used a length of 512.\n",
        "MAX_LEN = 256\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(\n",
        "    [tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "    maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\"\n",
        "    )\n",
        "\n",
        "# Index Numbers and Padding\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# pad sentences\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n",
        "                          dtype =\"long\", truncating=\"post\",padding =\"post\")\n",
        "\n",
        "# Attention masks\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i > 0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "prediction_data = \\\n",
        "  TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = \\\n",
        "  DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "uRq5ovsj5lD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on the test set\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask , b_labels = batch\n",
        "  # Telling the model not to compute or store gradients,\n",
        "  # saving memory and speeding up prediction\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to(\"cpu\").numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)"
      ],
      "metadata": {
        "id": "Rwnqpo_nB076"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Each Test Batch using Matthew's correlation coefficient\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  matthews = matthews_corrcoef(true_labels[i],\n",
        "                               np.argmax(predictions[i], axis=1).flatten())\n",
        "\n",
        "  matthews_set.append(matthews)\n",
        "\n",
        "matthews_set"
      ],
      "metadata": {
        "id": "pmTvEErRCI92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1420a440-d945-4f52-fee9-035f363d919f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13483997249264842,\n",
              " 0.048647332992624304,\n",
              " 0.31814238148788887,\n",
              " 0.1286949299057178,\n",
              " 0.060522753266880246,\n",
              " 0.29554655870445345,\n",
              " 0.3872983346207417,\n",
              " 0.3316863613133475,\n",
              " 0.3307292642388204,\n",
              " 0.24039295346263034,\n",
              " 0.5067911605056783,\n",
              " 0.3567530340063379,\n",
              " 0.1814627428602745,\n",
              " 0.3803921568627451,\n",
              " 0.1807753815155468,\n",
              " -0.011953709238683663,\n",
              " 0.19738550848793068,\n",
              " 0.1773241389867146,\n",
              " 0.00857966199371452,\n",
              " 0.4236592728681617,\n",
              " 0.10822510822510822,\n",
              " 0.11500161355436699,\n",
              " 0.374943053707453,\n",
              " 0.2886751345948129,\n",
              " 0.011953709238683663,\n",
              " -0.25308553412176554,\n",
              " 0.21821789023599236,\n",
              " 0.26967994498529685,\n",
              " -0.1286949299057178,\n",
              " 0.0,\n",
              " 0.01642880193633814,\n",
              " 0.11891767800211263,\n",
              " 0.21469801604867728,\n",
              " 0.5479936938801236,\n",
              " 0.05855400437691199,\n",
              " 0.2792896329177484,\n",
              " 0.048507125007266595,\n",
              " 0.5238095238095238,\n",
              " 0.5174307236488221,\n",
              " -0.08973031700969425,\n",
              " 0.3730235484764954,\n",
              " 0.26226526415648105,\n",
              " 0.12909944487358055,\n",
              " -0.050964719143762556,\n",
              " 0.06666666666666667,\n",
              " 0.5266597241998389,\n",
              " 0.030467917928916295,\n",
              " 0.4107200484084535,\n",
              " 0.07273929674533079,\n",
              " -0.021591675854376522,\n",
              " 0.2889738156210036,\n",
              " 0.44971201491459334,\n",
              " 0.20851441405707474,\n",
              " 0.07984636960487998,\n",
              " 0.4729696357398171,\n",
              " 0.22179547112466663,\n",
              " 0.4107200484084535,\n",
              " 0.14886529895627457,\n",
              " 0.07273929674533079,\n",
              " 0.4547940268270977,\n",
              " 0.08973031700969425,\n",
              " 0.32025630761017426,\n",
              " 0.13945994111797608,\n",
              " 0.29012942659282975,\n",
              " 0.24305875451990117,\n",
              " 0.2669661729972685,\n",
              " -0.07116958850708793,\n",
              " 0.24309494690922778,\n",
              " 0.24809590313546126,\n",
              " 0.19088542889273333,\n",
              " 0.10881399260327249,\n",
              " 0.42040343769201144,\n",
              " 0.16012815380508713,\n",
              " 0.48454371185234896,\n",
              " 0.1088776457161647,\n",
              " -0.09288407280256479,\n",
              " 0.1905246652387925,\n",
              " -0.0592864861199925,\n",
              " 0.2669661729972685,\n",
              " 0.33954987505086615,\n",
              " -0.26590801173915524,\n",
              " 0.44539933408304444,\n",
              " 0.048507125007266595,\n",
              " 0.5266354311522131,\n",
              " 0.32539568672798425,\n",
              " 0.16012815380508713,\n",
              " 0.31311214554257477,\n",
              " 0.48038446141526137,\n",
              " 0.20513587275572404,\n",
              " 0.3133397807202561,\n",
              " 0.3968253968253968,\n",
              " 0.1088776457161647,\n",
              " 0.14886529895627457,\n",
              " 0.20851441405707474,\n",
              " 0.2856530694872366,\n",
              " -0.10822510822510822,\n",
              " 0.18367958959266126,\n",
              " 0.34752402342845795,\n",
              " 0.34470668367478197,\n",
              " -0.020601266687222692,\n",
              " 0.37056498639919355,\n",
              " 0.28880007514798783,\n",
              " 0.363696483726654,\n",
              " -0.22084711628963774,\n",
              " 0.15289415743128767,\n",
              " 0.4526019054848144,\n",
              " 0.14785921742704325,\n",
              " 0.40451991747794525,\n",
              " 0.34470668367478197,\n",
              " -0.055227791305300936,\n",
              " 0.34188172937891387,\n",
              " -0.04222003309207491,\n",
              " 0.38737781366765006,\n",
              " -0.29012942659282975,\n",
              " 0.2669661729972685,\n",
              " 0.33910215700436014,\n",
              " 0.3072117917126884,\n",
              " 0.02486823656509969,\n",
              " 0.07273929674533079,\n",
              " -0.048647332992624304,\n",
              " 0.3280209083173944,\n",
              " 0.21821789023599236,\n",
              " 0.36507936507936506,\n",
              " -0.1619047619047619,\n",
              " 0.32277655457716287,\n",
              " 0.14285714285714285,\n",
              " 0.3779644730092272,\n",
              " 0.2164437316097468,\n",
              " 0.1901668471529859,\n",
              " 0.12909944487358055,\n",
              " 0.13483997249264842,\n",
              " 0.38737781366765006,\n",
              " 0.5114083119567587,\n",
              " 0.22084711628963774,\n",
              " 0.3759112094884605,\n",
              " 0.5636018619766345,\n",
              " 0.34097520463683817,\n",
              " 0.37254901960784315,\n",
              " 0.3072117917126884,\n",
              " 0.16974982846110506,\n",
              " 0.21019754169815524,\n",
              " 0.04222003309207491,\n",
              " 0.10776235844876533,\n",
              " 0.14907119849998599,\n",
              " 0.4980392156862745,\n",
              " -0.17785945835997752,\n",
              " 0.020601266687222692,\n",
              " 0.15749883157896472,\n",
              " 0.12909944487358055,\n",
              " 0.4040950971038548,\n",
              " 0.06666666666666667,\n",
              " 0.08818077954471167,\n",
              " 0.21019754169815524,\n",
              " 0.14785921742704325,\n",
              " 0.4290823322857326,\n",
              " 0.3578300267477955,\n",
              " 0.38297084310253526,\n",
              " 0.055227791305300936,\n",
              " 0.09169839395065688,\n",
              " 0.06362847629757777,\n",
              " -0.11124684011100254,\n",
              " 0.07273929674533079,\n",
              " 0.4248710287154289,\n",
              " 0.040082172520323485,\n",
              " 0.18993429409939658,\n",
              " -0.0821256038647343,\n",
              " 0.15244937348544793,\n",
              " 0.1972421118046462,\n",
              " 0.1773241389867146,\n",
              " -0.06465741506925919,\n",
              " 0.4161455870818984,\n",
              " -0.21821789023599236,\n",
              " 0.048507125007266595,\n",
              " 0.24039295346263034,\n",
              " 0.23354968324845687,\n",
              " 0.3730235484764954,\n",
              " -0.16974982846110506,\n",
              " -0.07984636960487998,\n",
              " 0.32277655457716287,\n",
              " 0.2856530694872366,\n",
              " 0.30508307783296046,\n",
              " 0.1905246652387925,\n",
              " 0.29277002188455997,\n",
              " 0.13483997249264842,\n",
              " 0.4161455870818984,\n",
              " 0.17785945835997752,\n",
              " -0.03253000243161777,\n",
              " 0.47306844125299624,\n",
              " 0.3333333333333333,\n",
              " 0.15244937348544793,\n",
              " 0.24705882352941178,\n",
              " 0.16974982846110506,\n",
              " 0.3460009349544799,\n",
              " 0.5222329678670935,\n",
              " 0.0849411985729376,\n",
              " 0.08084520834544433,\n",
              " 0.050964719143762556,\n",
              " 0.42040343769201144,\n",
              " -0.07116958850708793,\n",
              " 0.23329882422520506,\n",
              " 0.08084520834544433,\n",
              " 0.15289415743128767,\n",
              " 0.03673591791853225,\n",
              " 0.2164437316097468,\n",
              " 0.1814627428602745,\n",
              " 0.3280209083173944,\n",
              " 0.5393598899705937,\n",
              " 0.3768673314407159,\n",
              " 0.06279669574154817,\n",
              " 0.16005781417779466,\n",
              " 0.1868706368604627,\n",
              " 0.16974982846110506,\n",
              " 0.13261933174731558,\n",
              " 0.2519763153394848,\n",
              " 0.33062326126679026,\n",
              " 0.036155076303109365,\n",
              " 0.458682472293863,\n",
              " 0.4817813765182186,\n",
              " -0.15749883157896472,\n",
              " 0.498071218278486,\n",
              " 0.5056936741642399,\n",
              " 0.5659164584181102,\n",
              " 0.32025630761017426,\n",
              " 0.26967994498529685,\n",
              " 0.1286949299057178,\n",
              " 0.20602334873357925,\n",
              " 0.2549019607843137,\n",
              " -0.01642880193633814,\n",
              " 0.5601675975251952,\n",
              " 0.5553906166205598,\n",
              " 0.3509664885977756,\n",
              " 0.42276002160669474,\n",
              " 0.11020775375559676,\n",
              " 0.2548235957188128,\n",
              " 0.1111111111111111,\n",
              " 0.13483997249264842,\n",
              " 0.44539933408304444,\n",
              " 0.036155076303109365,\n",
              " 0.3063963871403498,\n",
              " -0.14285714285714285,\n",
              " 0.2842974802836732,\n",
              " 0.49206349206349204,\n",
              " -0.013719241215239542,\n",
              " 0.22179547112466663,\n",
              " 0.22084711628963774,\n",
              " 0.17785945835997752,\n",
              " 0.2842974802836732,\n",
              " -0.18367958959266126,\n",
              " 0.12941176470588237,\n",
              " 0.36507936507936506,\n",
              " 0.0849411985729376,\n",
              " 0.16005781417779466,\n",
              " 0.06279669574154817,\n",
              " 0.1773241389867146,\n",
              " 0.34097520463683817,\n",
              " 0.3133397807202561,\n",
              " 0.2842974802836732,\n",
              " 0.18367958959266126,\n",
              " 0.29277002188455997,\n",
              " 0.2238141290858972,\n",
              " -0.1259881576697424,\n",
              " 0.14886529895627457,\n",
              " 0.09288407280256479,\n",
              " 0.14433756729740646,\n",
              " 0.20851441405707474,\n",
              " 0.4177371279974369,\n",
              " 0.5986618327360926,\n",
              " 0.07246376811594203,\n",
              " 0.09288407280256479,\n",
              " 0.31814238148788887,\n",
              " 0.3124282448813543,\n",
              " 0.23175626392360707,\n",
              " 0.37056498639919355,\n",
              " 0.07100716024967263,\n",
              " 0.1218363373750322,\n",
              " 0.17796484599023626,\n",
              " 0.33910215700436014,\n",
              " 0.397705839334203,\n",
              " -0.011953709238683663,\n",
              " 0.3072117917126884,\n",
              " 0.2,\n",
              " -0.04222003309207491,\n",
              " 0.37796447300922725,\n",
              " 0.1303589814791738,\n",
              " 0.3307292642388204,\n",
              " 0.07116958850708793,\n",
              " 0.13135173437318345,\n",
              " 0.30903173899329384,\n",
              " 0.14886529895627457,\n",
              " -0.08084520834544433,\n",
              " 0.008756782291545563,\n",
              " 0.4729696357398171,\n",
              " 0.030467917928916295,\n",
              " 0.28312884579257913,\n",
              " 0.14285714285714285,\n",
              " 0.13483997249264842,\n",
              " -0.06279669574154817,\n",
              " 0.06279669574154817,\n",
              " 0.22179547112466663,\n",
              " 0.34470668367478197,\n",
              " 0.3072117917126884,\n",
              " 0.3289758474798845,\n",
              " 0.0849411985729376,\n",
              " -0.12909944487358055,\n",
              " 0.26967994498529685,\n",
              " 0.14433756729740646,\n",
              " 0.33910215700436014,\n",
              " 0.7562449037944323,\n",
              " 0.2886751345948129,\n",
              " 0.09449929894737882,\n",
              " 0.09287218116773731,\n",
              " 0.06666666666666667,\n",
              " 0.2581988897471611]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "matthews_corrcoef(flat_true_labels , flat_predictions)"
      ],
      "metadata": {
        "id": "776yeDnFCNiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62177865-d771-4fcf-8c78-8ff029b35f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2073370259165254"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'bert-based-uncased-GED.pth')"
      ],
      "metadata": {
        "id": "KFpirIm8WS3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QjWF9S7HWWKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59eba397-6622-4d8f-b41a-081ee1806a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp bert-based-uncased-GED.pth './drive/My Drive/Colab Notebooks/S89A'"
      ],
      "metadata": {
        "id": "olBzvxrLWlaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run on a sample text\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Create sentence) and label lists\n",
        "sentences = [\"They drank the pub.\"]\n",
        "# We need to add special tokens at the beginning and end of each sentence\n",
        "# for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels =[0]\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "# Padding Sentences\n",
        "# Set the maximum sequence length. The longest sequence in our training set\n",
        "# is 47, but we'll leave room on the end anyway.\n",
        "# In the original paper, the authors used a length of 512.\n",
        "MAX_LEN = 256\n",
        "\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(\n",
        "    [tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "    maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\"\n",
        "    )\n",
        "\n",
        "# Index Numbers and Padding\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# pad sentences\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n",
        "                          dtype =\"long\", truncating=\"post\",padding =\"post\")\n",
        "\n",
        "# Attention masks\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i > 0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "print(prediction_inputs)\n",
        "print(prediction_masks)\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  # Forward pass, calculate logit predictions\n",
        "  logits = model(prediction_inputs.to(device), token_type_ids=None, attention_mask=prediction_masks.to(device))\n",
        "\n",
        "# Move logits and labels to CPU\n",
        "logits = logits.detach().cpu().numpy()\n",
        "label_ids = b_labels.to(\"cpu\").numpy()\n",
        "\n",
        "# Store predictions and true labels\n",
        "predictions.append(logits)\n",
        "true_labels.append(label_ids)\n",
        "\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a6UD0B3OmFO",
        "outputId": "eabdad2a-d532-407f-d529-9b08e74afc75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  2027, 10749,  1996,  9047,  1012,   102,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]])\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gputil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zly1eUHAQHpI",
        "outputId": "691f663b-eb84-4622-96b4-dbd8be859116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=2860f446c5f17ba6b53d8ec72a0dbb5016ae228ecbaa2b82529277e124159ad1\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run on a sample text\n",
        "\n",
        "import torch\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "from numba import cuda\n",
        "\n",
        "def free_gpu_cache():\n",
        "    print(\"Initial GPU Usage\")\n",
        "    gpu_usage()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    cuda.select_device(0)\n",
        "    cuda.close()\n",
        "    cuda.select_device(0)\n",
        "\n",
        "    print(\"GPU Usage after emptying the cache\")\n",
        "    gpu_usage()\n",
        "\n",
        "#free_gpu_cache()\n",
        "\n",
        "test = pd.read_csv(\"test_data.csv\")\n",
        "sentences=[\"I am hero\"]\n",
        "for i in range(len(test['input'])):\n",
        "    sentences.append(test['input'][i])\n",
        "\n",
        "#model.eval()\n",
        "\n",
        "# Create sentence) and label lists\n",
        "# We need to add special tokens at the beginning and end of each sentence\n",
        "# for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels =[0]\n",
        "#print(sentences)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "#print(tokenized_texts)\n",
        "# Padding Sentences\n",
        "# Set the maximum sequence length. The longest sequence in our training set\n",
        "# is 47, but we'll leave room on the end anyway.\n",
        "# In the original paper, the authors used a length of 512.\n",
        "MAX_LEN = 256\n",
        "\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(\n",
        "    [tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "    maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\"\n",
        "    )\n",
        "\n",
        "# Index Numbers and Padding\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "#print(input_ids)\n",
        "# pad sentences\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n",
        "                          dtype =\"long\", truncating=\"post\",padding =\"post\")\n",
        "#print(input_ids)\n",
        "\n",
        "#print(len(input_ids))\n",
        "# Attention masks\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i > 0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "batch_size = 32\n",
        "\n",
        "prediction_data = \\\n",
        "  TensorDataset(prediction_inputs, prediction_masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = \\\n",
        "  DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "#print(prediction_masks)\n",
        "#print(prediction_inputs.shape)\n",
        "#print(prediction_masks.shape)\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  # Forward pass, calculate logit predictions\n",
        "  for prediction_input,prediction_mask in prediction_dataloader:\n",
        "    logits = model(prediction_input.to(device), token_type_ids=None, attention_mask=prediction_mask.to(device))\n",
        "\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "print(flat_predictions)\n"
      ],
      "metadata": {
        "id": "_xkQRMZkCT2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aac1d05-89f5-4d08-ce62-86659d6afcc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (866 > 512). Running this sequence through BERT will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (866 > 512). Running this sequence through BERT will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/test_NEW_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "WzJHDFaRMPHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score,recall_score,f1_score"
      ],
      "metadata": {
        "id": "fKgO2avipfOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_score(y_test,y_pred1,average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "kQ-Z5KtMpe1D",
        "outputId": "b1e717bc-984e-4bf0-c5de-cde49366a8db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-864ae4da31c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yeCtIYi1peh-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}