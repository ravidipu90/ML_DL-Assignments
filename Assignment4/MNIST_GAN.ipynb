{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "import functools\n",
    "from torch.nn import init\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import imageio\n",
    "import natsort\n",
    "import logging\n",
    "import itertools\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.name = 'DCGAN'\n",
    "        self.dataset_name = 'MNIST'\n",
    "        self.output_path = './results/'\n",
    "        \n",
    "        self.num_workers = 8\n",
    "        self.batch_size = 32\n",
    "        self.num_epochs = 50\n",
    "        self.ndf = 32\n",
    "        self.ngf = 32\n",
    "        self.nz = 100\n",
    "        self.d_lr = 0.0002\n",
    "        self.g_lr = 0.0002\n",
    "        self.nc = 1\n",
    "        self.fps = 5\n",
    "        self.use_fixed = True\n",
    "        self.weight_decay = 1e-4\n",
    "        self.num_test_samples = 16\n",
    "        self.num_r_samples = 16\n",
    "        \n",
    "        os.makedirs(self.output_path,exist_ok=True)\n",
    "opt = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(batch_size):\n",
    "    # MNIST Dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.1307, ), std=(0.3081, ))])\n",
    "\n",
    "    train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
    "\n",
    "    # Data Loader\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(net, init_type='normal', init_gain=0.02, debug=False):\n",
    "    \n",
    "    def init_func(m):  # define the initialization function\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            if debug:\n",
    "                print(classname)\n",
    "            if init_type == 'normal':\n",
    "                init.normal_(m.weight.data, 0.0, init_gain)\n",
    "            elif init_type == 'xavier':\n",
    "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
    "            elif init_type == 'kaiming':\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            elif init_type == 'orthogonal':\n",
    "                init.orthogonal_(m.weight.data, gain=init_gain)\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "        elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "            init.normal_(m.weight.data, 1.0, init_gain)\n",
    "            init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    net.apply(init_func)  # apply the initialization function <init_func>\n",
    "\n",
    "\n",
    "\n",
    "def init_net(net, init_type='normal', init_gain=0.02, gpu_ids=[], debug=False, initialize_weights=True):\n",
    "    if len(gpu_ids) > 0:\n",
    "        assert(torch.cuda.is_available())\n",
    "        net.to(gpu_ids[0])\n",
    "    if initialize_weights:\n",
    "        init_weights(net, init_type, init_gain=init_gain, debug=debug)\n",
    "    return net\n",
    "def get_norm_layer(norm_type='instance'):\n",
    "   \n",
    "    if norm_type == 'batch':\n",
    "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
    "    elif norm_type == 'instance':\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
    "    elif norm_type == 'none':\n",
    "        def norm_layer(x):\n",
    "            return Identity()\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "    return norm_layer\n",
    "\n",
    "def define_G(input_nc, output_nc, ngf, netG, norm='batch', use_dropout=False, init_type='normal',\n",
    "             init_gain=0.02, no_antialias=False, no_antialias_up=False, gpu_ids=[], opt=None):\n",
    "    net = None\n",
    "    norm_layer = get_norm_layer(norm_type=norm)\n",
    "\n",
    "   \n",
    "    if netG == 'resnet_6blocks':\n",
    "        net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, no_antialias=no_antialias, no_antialias_up=no_antialias_up, n_blocks=6, opt=opt)\n",
    "    elif netG == 'resnet_4blocks':\n",
    "        net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, no_antialias=no_antialias, no_antialias_up=no_antialias_up, n_blocks=4, opt=opt)\n",
    "    \n",
    "    return init_net(net, init_type, init_gain, gpu_ids, initialize_weights=('stylegan2' not in netG))\n",
    "\n",
    "\n",
    "def get_filter(filt_size=3):\n",
    "    if(filt_size == 1):\n",
    "        a = np.array([1., ])\n",
    "    elif(filt_size == 2):\n",
    "        a = np.array([1., 1.])\n",
    "    elif(filt_size == 3):\n",
    "        a = np.array([1., 2., 1.])\n",
    "    elif(filt_size == 4):\n",
    "        a = np.array([1., 3., 3., 1.])\n",
    "    elif(filt_size == 5):\n",
    "        a = np.array([1., 4., 6., 4., 1.])\n",
    "    elif(filt_size == 6):\n",
    "        a = np.array([1., 5., 10., 10., 5., 1.])\n",
    "    elif(filt_size == 7):\n",
    "        a = np.array([1., 6., 15., 20., 15., 6., 1.])\n",
    "\n",
    "    filt = torch.Tensor(a[:, None] * a[None, :])\n",
    "    filt = filt / torch.sum(filt)\n",
    "\n",
    "    return filt\n",
    "\n",
    "def get_pad_layer(pad_type):\n",
    "    if(pad_type in ['refl', 'reflect']):\n",
    "        PadLayer = nn.ReflectionPad2d\n",
    "    elif(pad_type in ['repl', 'replicate']):\n",
    "        PadLayer = nn.ReplicationPad2d\n",
    "    elif(pad_type == 'zero'):\n",
    "        PadLayer = nn.ZeroPad2d\n",
    "    else:\n",
    "        print('Pad type [%s] not recognized' % pad_type)\n",
    "    return PadLayer\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, channels, pad_type='reflect', filt_size=3, stride=2, pad_off=0):\n",
    "        super(Downsample, self).__init__()\n",
    "        self.filt_size = filt_size\n",
    "        self.pad_off = pad_off\n",
    "        self.pad_sizes = [int(1. * (filt_size - 1) / 2), int(np.ceil(1. * (filt_size - 1) / 2)), int(1. * (filt_size - 1) / 2), int(np.ceil(1. * (filt_size - 1) / 2))]\n",
    "        self.pad_sizes = [pad_size + pad_off for pad_size in self.pad_sizes]\n",
    "        self.stride = stride\n",
    "        self.off = int((self.stride - 1) / 2.)\n",
    "        self.channels = channels\n",
    "\n",
    "        filt = get_filter(filt_size=self.filt_size)\n",
    "        self.register_buffer('filt', filt[None, None, :, :].repeat((self.channels, 1, 1, 1)))\n",
    "\n",
    "        self.pad = get_pad_layer(pad_type)(self.pad_sizes)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        if(self.filt_size == 1):\n",
    "            if(self.pad_off == 0):\n",
    "                return inp[:, :, ::self.stride, ::self.stride]\n",
    "            else:\n",
    "                return self.pad(inp)[:, :, ::self.stride, ::self.stride]\n",
    "        else:\n",
    "            return F.conv2d(self.pad(inp), self.filt, stride=self.stride, groups=inp.shape[1])\n",
    "\n",
    "class ResBlocks(nn.Module):\n",
    "    def __init__(self, num_blocks, dim, norm='inst', activation='relu', pad_type='zero', nz=0):\n",
    "        super(ResBlocks, self).__init__()\n",
    "        self.model = []\n",
    "        for i in range(num_blocks):\n",
    "            self.model += [ResBlock(dim, norm=norm, activation=activation, pad_type=pad_type, nz=nz)]\n",
    "        self.model = nn.Sequential(*self.model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "\n",
    "class ResnetGenerator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect', no_antialias=False, no_antialias_up=False, opt=None):\n",
    "        assert(n_blocks >= 0)\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "        self.opt = opt\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        model = [nn.ReflectionPad2d(1),\n",
    "                 nn.Conv2d(input_nc, ngf, kernel_size=3, padding=0, bias=use_bias),\n",
    "                 norm_layer(ngf),\n",
    "                 nn.ReLU(True)]\n",
    "\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):  # add downsampling layers\n",
    "            mult = 2 ** i\n",
    "            if(no_antialias):\n",
    "                model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                          norm_layer(ngf * mult * 2),\n",
    "                          nn.ReLU(True)]\n",
    "            else:\n",
    "                model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=1, padding=1, bias=use_bias),\n",
    "                          norm_layer(ngf * mult * 2),\n",
    "                          nn.ReLU(True),\n",
    "                          Downsample(ngf * mult * 2)]\n",
    "\n",
    "        mult = 2 ** n_downsampling\n",
    "        for i in range(n_blocks):       # add ResNet blocks\n",
    "\n",
    "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
    "\n",
    "        for i in range(n_downsampling):  # add upsampling layers\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            if no_antialias_up:\n",
    "                model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                             kernel_size=3, stride=2,\n",
    "                                             padding=1, output_padding=1,\n",
    "                                             bias=use_bias),\n",
    "                          norm_layer(int(ngf * mult / 2)),\n",
    "                          nn.ReLU(True)]\n",
    "            else:\n",
    "                model += [Upsample(ngf * mult),\n",
    "                          nn.Conv2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                    kernel_size=3, stride=1,\n",
    "                                    padding=1,  # output_padding=1,\n",
    "                                    bias=use_bias),\n",
    "                          norm_layer(int(ngf * mult / 2)),\n",
    "                          nn.ReLU(True)]\n",
    "        model += [nn.ReflectionPad2d(1)]\n",
    "        model += [nn.Conv2d(ngf, output_nc, kernel_size=3, padding=0)]\n",
    "        model += [nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, input, layers=[], encode_only=False):\n",
    "        if -1 in layers:\n",
    "            layers.append(len(self.model))\n",
    "        if len(layers) > 0:\n",
    "            feat = input\n",
    "            feats = []\n",
    "            for layer_id, layer in enumerate(self.model):\n",
    "                # print(layer_id, layer)\n",
    "                feat = layer(feat)\n",
    "                if layer_id in layers:\n",
    "                    # print(\"%d: adding the output of %s %d\" % (layer_id, layer.__class__.__name__, feat.size(1)))\n",
    "                    feats.append(feat)\n",
    "                else:\n",
    "                    # print(\"%d: skipping %s %d\" % (layer_id, layer.__class__.__name__, feat.size(1)))\n",
    "                    pass\n",
    "                if layer_id == layers[-1] and encode_only:\n",
    "                    # print('encoder only return features')\n",
    "                    return feats  # return intermediate features alone; stop in the last layers\n",
    "\n",
    "            return feat, feats  # return both output and intermediate features\n",
    "        else:\n",
    "            \"\"\"Standard forward\"\"\"\n",
    "            fake = self.model(input)\n",
    "            return fake\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"Define a Resnet block\"\"\"\n",
    "\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function (with skip connections)\"\"\"\n",
    "        out = x + self.conv_block(x)  # add skip connections\n",
    "        return out\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, channels, pad_type='repl', filt_size=4, stride=2):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.filt_size = filt_size\n",
    "        self.filt_odd = np.mod(filt_size, 2) == 1\n",
    "        self.pad_size = int((filt_size - 1) / 2)\n",
    "        self.stride = stride\n",
    "        self.off = int((self.stride - 1) / 2.)\n",
    "        self.channels = channels\n",
    "\n",
    "        filt = get_filter(filt_size=self.filt_size) * (stride**2)\n",
    "        self.register_buffer('filt', filt[None, None, :, :].repeat((self.channels, 1, 1, 1)))\n",
    "\n",
    "        self.pad = get_pad_layer(pad_type)([1, 1, 1, 1])\n",
    "\n",
    "    def forward(self, inp):\n",
    "        ret_val = F.conv_transpose2d(self.pad(inp), self.filt, stride=self.stride, padding=1 + self.pad_size, groups=inp.shape[1])[:, :, 1:, 1:]\n",
    "        if(self.filt_odd):\n",
    "            return ret_val\n",
    "        else:\n",
    "            return ret_val[:, :, :-1, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nc=1\n",
    "output_nc=1\n",
    "ngf=32                 # of gen filters in the last conv layer\n",
    "netG = 'resnet_6blocks' \n",
    "init_type ='xavier'    # choices=['normal', 'xavier', 'kaiming', 'orthogonal'], help='network initialization')\n",
    "init_gain = 0.02       #'scaling factor for normal, xavier and orthogonal.')\n",
    "no_antialias = True    #if specified, use stride=2 convs instead of antialiased-downsampling \n",
    "no_antialias_up = True #if specified, use [upconv(learned filter)] instead of [upconv(hard-coded [1,3,3,1] filter), conv]\n",
    "\n",
    "netG=define_G(input_nc, output_nc, ngf, netG, norm='batch', use_dropout=False, init_type='normal',\n",
    "             init_gain=0.02, no_antialias=False, no_antialias_up=False, gpu_ids=[], opt=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, in_channels, num_channels):\n",
    "    layers=[]\n",
    "    for i in range(num_convs):\n",
    "        layers+=[nn.Conv2d(in_channels=in_channels, out_channels=num_channels, kernel_size=3, padding=2)]\n",
    "        in_channels=num_channels\n",
    "    layers +=[nn.ReLU()]\n",
    "    layers +=[nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "    return nn.Sequential(*layers)\n",
    " \n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG,self).__init__()\n",
    "        self.conv_arch=((1,1,64),(1,64,128),(2,128,256),(2,256,512),(2,512,512))\n",
    "        layers=[]\n",
    "        for (num_convs,in_channels,num_channels) in self.conv_arch:\n",
    "            layers+=[vgg_block(num_convs,in_channels,num_channels)]\n",
    "        self.features=nn.Sequential(*layers)\n",
    "        self.dense1 = nn.Linear(512*4*4,4096)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.Linear(4096, 4096)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        self.dense3 = nn.Linear(4096, 1)\n",
    " \n",
    "    def forward(self,x):\n",
    "        x=self.features(x)\n",
    "        x=x.view(-1,512*4*4)\n",
    "        x=self.dense3(self.drop2(F.relu(self.dense2(self.drop1(F.relu(self.dense1(x)))))))\n",
    "        x=torch.sigmoid(x)\n",
    "        return x\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_data_loader(opt.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = {}\n",
    "train_hist['D_losses'] = []\n",
    "train_hist['G_losses'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = {}\n",
    "train_hist['D_losses'] = []\n",
    "train_hist['G_losses'] = []\n",
    "\n",
    "def show_train_hist(hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "    x = range(len(hist['D_losses']))\n",
    "\n",
    "    y1 = hist['D_losses']\n",
    "    y2 = hist['G_losses']\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss')\n",
    "    plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Iter')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(epoch, path, fixed_noise, num_test_samples, netG, device, use_fixed):\n",
    "    \n",
    "    r_z = []\n",
    "    for i in range(10):\n",
    "        z = torch.randn(num_test_samples, 1, 28, 28, device=device)\n",
    "        r_z.append(z)\n",
    "        \n",
    "    size_figure_grid = int(math.sqrt(num_test_samples))\n",
    "    title = None\n",
    "  \n",
    "    generated_fake_images =[]\n",
    "    if use_fixed:\n",
    "        f_out = netG(fixed_noise)\n",
    "        generated_fake_images.append(f_out)\n",
    "        path += 'fixed_noise/'\n",
    "        os.makedirs(path,exist_ok=True)\n",
    "        title = 'Fixed Noise'\n",
    "        \n",
    "    if not use_fixed:\n",
    "        for z_ in r_z:\n",
    "            r_out = netG(z_)\n",
    "            generated_fake_images.append(r_out)\n",
    "        path += 'variable_noise/' \n",
    "        os.makedirs(path,exist_ok=True)\n",
    "        title = 'Variable Noise'\n",
    "\n",
    "    fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6,6))\n",
    "    for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "        ax[i,j].get_xaxis().set_visible(False)\n",
    "        ax[i,j].get_yaxis().set_visible(False)\n",
    "     \n",
    "    i=0\n",
    "    for gen in generated_fake_images:\n",
    "        for k in range(num_test_samples):\n",
    "            i = k//4\n",
    "            j = k%4\n",
    "            ax[i,j].cla()\n",
    "            ax[i,j].imshow(gen[k].data.cpu().numpy().reshape(28,28), cmap='Greys')\n",
    "\n",
    "        if use_fixed:    \n",
    "            label = 'Epoch_{}'.format(epoch+1)\n",
    "            fig.text(0.5, 0.04, label, ha='center')\n",
    "            fig.suptitle(title)\n",
    "            fig.savefig(path+label+'.png')\n",
    "        else:\n",
    "            label = 'Epoch_{}_{}'.format(epoch+1,i)\n",
    "            fig.text(0.5, 0.04, label, ha='center')\n",
    "            fig.suptitle(title)\n",
    "            fig.savefig(path+label+'.png')\n",
    "            i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gif(path, fps, fixed_noise=False):\n",
    "    if fixed_noise==True:\n",
    "        path += 'fixed_noise/'\n",
    "    else:\n",
    "        path += 'variable_noise/'\n",
    "    images = glob(path + '*.png')\n",
    "    images = natsort.natsorted(images)\n",
    "    gif = []\n",
    "\n",
    "    for image in images:\n",
    "        gif.append(imageio.imread(image))\n",
    "    imageio.mimsave(path+'animated.gif', gif, fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG =netG.to(device)\n",
    "netD = VGG().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=opt.d_lr)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=opt.g_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1\n",
    "fake_label = 0\n",
    "num_batches = len(train_loader)\n",
    "fixed_noise = torch.randn(opt.num_test_samples, 1, 28, 28, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    state = torch.load(os.path.join('results','kl', 'models.pth'),map_location='cuda:1')\n",
    "    netG.load_state_dict(state['g_state'])\n",
    "    print(\"Pretained models loaded successfully\")\n",
    "except:\n",
    "    print(\"Training from scratch\")\n",
    "\n",
    "\n",
    "num_iter = 0\n",
    "D_losses = []\n",
    "G_losses  = []\n",
    "for epoch in range(opt.num_epochs):\n",
    "    for i, (real_images, _) in enumerate(train_loader):\n",
    "        bs = real_images.shape[0]\n",
    "        y_real = torch.ones(bs).to(device)\n",
    "        y_fake = torch.zeros(bs).to(device)  \n",
    "        ##############################\n",
    "        #   Training discriminator   #\n",
    "        ##############################\n",
    "\n",
    "        netD.zero_grad()\n",
    "        real_images = real_images.to(device)\n",
    "#         label = torch.full((bs,), real_label, device=device)\n",
    "\n",
    "        output = netD(real_images).squeeze()\n",
    "        lossD_real = criterion(output, y_real)\n",
    "        lossD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        noise = torch.randn(bs, 1, 28, 28, device=device)\n",
    "        fake_images = netG(noise)\n",
    "        \n",
    "#         label.fill_(fake_label)\n",
    "        output = netD(fake_images.detach()).squeeze()\n",
    "        lossD_fake = criterion(output, y_fake)\n",
    "        lossD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        lossD = lossD_real + lossD_fake\n",
    "        optimizerD.step()\n",
    "        D_losses.append(lossD.item())\n",
    "\n",
    "        ##########################\n",
    "        #   Training generator   #\n",
    "        ##########################\n",
    "\n",
    "        netG.zero_grad()\n",
    "#         label.fill_(real_label)\n",
    "        fake_images = netG(noise)\n",
    "        output = netD(fake_images.detach()).squeeze()\n",
    "        lossG = criterion(output, y_real)\n",
    "        lossG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "        num_iter += 1\n",
    "        G_losses.append(lossG.item())\n",
    "        if (i+1)%300 == 0:\n",
    "            print('Epoch [{}/{}], step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, Discriminator - D(G(x)): {:.2f}, Generator - D(G(x)): {:.2f}'.format(epoch+1, opt.num_epochs, \n",
    "                                                        i+1, num_batches, lossD.item(), lossG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        netG.eval()\n",
    "        generate_images(epoch, opt.output_path, fixed_noise, opt.num_test_samples, netG, device, use_fixed=opt.use_fixed)\n",
    "        generate_images(epoch, opt.output_path, fixed_noise, opt.num_r_samples, netG, device, use_fixed=False)\n",
    "        netG.train()\n",
    "        train_hist['D_losses'].append(torch.mean(torch.FloatTensor(D_losses)))\n",
    "        train_hist['G_losses'].append(torch.mean(torch.FloatTensor(G_losses)))\n",
    "\n",
    "    # Save gif:\n",
    "    save_gif(opt.output_path, opt.fps, fixed_noise=opt.use_fixed)\n",
    "    \n",
    "    state = {\n",
    "                'epoch': epoch,\n",
    "                'g_state': netG.state_dict(),\n",
    "                'd_state': netD.state_dict(),\n",
    "                }\n",
    "    torch.save(state, \"./results/dc_gan.pth\")\n",
    "    if epoch == 0:\n",
    "        torch.save(state, \"./results/models_0.pth\")\n",
    "    if epoch == opt.num_epochs/2:\n",
    "        torch.save(state, \"./results/models_n/2.pth\")\n",
    "    \n",
    "\n",
    "show_train_hist(train_hist, save=True, path='./results/MNIST_DCGAN_train_hist.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
